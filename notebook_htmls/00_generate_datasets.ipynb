{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75215891",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Title: 00a_wweia_fda_ingredients_2023\n",
    "### Purpose: Generate four WWEIA datasets: mixed meals, food categories, total nutrients, ingredients\n",
    "### Date: July 24, 2024\n",
    "### Author: Jules Larke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd783d5-23aa-4663-8f1b-3c7ce1a388bb",
   "metadata": {},
   "source": [
    "### Read in NHANES data for cycles 2003 - 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d3309a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download & Read SAS Transport Files from web\n",
      "Finished downloading NHANES files\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "print('Download & Read SAS Transport Files from web') \n",
    "# Demographic, Dietary day 1, and Food description data for cycles 03 through 18\n",
    "\n",
    "demo_C = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2003/DataFiles/demo_c.xpt', format='xport', encoding='utf-8')\n",
    "iff_1_C = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2003/DataFiles/dr1iff_c.xpt', format='xport', encoding='utf-8')\n",
    "iff_2_C = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2003/DataFiles/dr2iff_c.xpt', format='xport', encoding='utf-8')\n",
    "food_desc_C = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2003/DataFiles/drxfcd_c.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "demo_D = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2005/DataFiles/demo_d.xpt', format='xport', encoding='utf-8')\n",
    "iff_1_D = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2005/DataFiles/dr1iff_d.xpt', format='xport', encoding='utf-8')\n",
    "iff_2_D = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2005/DataFiles/dr2iff_d.xpt', format='xport', encoding='utf-8')\n",
    "food_desc_D = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2005/DataFiles/drxfcd_d.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "demo_E = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2007/DataFiles/DEMO_E.xpt', format='xport', encoding='utf-8')\n",
    "iff_1_E = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2007/DataFiles/DR1IFF_E.xpt', format='xport', encoding='utf-8')\n",
    "iff_2_E = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2007/DataFiles/DR2IFF_E.xpt', format='xport', encoding='utf-8')\n",
    "food_desc_E = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2007/DataFiles/drxfcd_e.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "demo_F = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2009/DataFiles/DEMO_f.xpt', format='xport', encoding='utf-8')\n",
    "iff_1_F = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2009/DataFiles/DR1IFF_f.xpt', format='xport', encoding='utf-8')\n",
    "iff_2_F = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2009/DataFiles/DR2IFF_f.xpt', format='xport', encoding='utf-8')\n",
    "food_desc_F = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2009/DataFiles/drxfcd_f.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "demo_G = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2011/DataFiles/DEMO_g.xpt', format='xport', encoding='utf-8')\n",
    "iff_1_G = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/nhanes/Public/2011/DataFiles/DR1IFF_G.XPT', format='xport', encoding='utf-8')\n",
    "iff_2_G = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/nhanes/Public/2011/DataFiles/DR2IFF_g.xpt', format='xport', encoding='utf-8')\n",
    "food_desc_G = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2011/DataFiles/drxfcd_g.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "demo_H = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2013/DataFiles/DEMO_h.xpt', format='xport', encoding='utf-8')\n",
    "iff_1_H = pd.read_sas('https://wwwn.cdc.gov/nchs/Data/nhanes/Public/2013/DataFiles/DR1IFF_H.XPT', format='xport', encoding='utf-8')\n",
    "iff_2_H = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2013/DataFiles/DR2IFF_h.xpt', format='xport', encoding='utf-8')\n",
    "food_desc_H = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2013/DataFiles/drxfcd_h.xpt', format='xport', encoding='latin-1') # error: 'utf-8' codec can't decode. using 'latin-1' works\n",
    "\n",
    "demo_I = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2015/DataFiles/DEMO_I.xpt', format='xport', encoding='utf-8')\n",
    "iff_1_I = pd.read_sas('https://wwwn.cdc.gov/nchs/Data/nhanes/Public/2015/DataFiles/DR1IFF_I.XPT', format='xport', encoding='utf-8')\n",
    "iff_2_I = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2015/DataFiles/DR2IFF_I.xpt', format='xport', encoding='utf-8')\n",
    "food_desc_I = pd.read_sas('https://wwwn.cdc.gov/NCHS/Data/nhanes/Public/2015/DataFiles/drxfcd_i.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "demo_P = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/P_DEMO.xpt', format='xport', encoding='utf-8')\n",
    "iff_1_P = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/P_DR1IFF.xpt', format='xport', encoding='utf-8')\n",
    "iff_2_P = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/P_DR2IFF.xpt', format='xport', encoding='utf-8')\n",
    "food_desc_P = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/P_DRXFCD.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "demo_L = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/DEMO_L.xpt', format='xport', encoding='utf-8')\n",
    "iff_1_L = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/DR1IFF_L.xpt', format='xport', encoding='utf-8')\n",
    "iff_2_L = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/DR2IFF_L.xpt', format='xport', encoding='utf-8')\n",
    "food_desc_L = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/DRXFCD_L.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "print('Finished downloading NHANES files') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89b2c4c-d6e9-4b42-bde1-f86d420a63f1",
   "metadata": {},
   "source": [
    "### Select variables of interest from demographic and dietary data for combining cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a50c59-e12e-487b-8e7d-2ace1745e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_C = demo_C[['SEQN', 'RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'RIDEXPRG', 'DMDBORN', 'INDFMPIR', 'DMDYRSUS', 'DMDEDUC3', 'DMDEDUC2', 'WTINT2YR', 'WTMEC2YR', 'SDMVPSU', 'SDMVSTRA']]\n",
    "iff_1_C = iff_1_C[['SEQN', 'DRDINT', 'DR1DRSTZ', 'DR1ILINE', 'DR1IFDCD', 'DR1_030Z', 'WTDRD1', 'WTDR2D', 'DR1IGRMS', 'DR1IKCAL', 'DR1ICARB', 'DR1ISUGR', 'DR1IFIBE', 'DR1IMOIS']].rename(columns={'DR1IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE', 'DR1IMOIS':'DR2IMOIS'}) # renaming to the day 2 feature names for averaging\n",
    "iff_1_C['diet_day'] = 1\n",
    "iff_2_C = iff_2_C[['SEQN', 'DRDINT', 'DR2DRSTZ', 'DR2ILINE', 'DR2IFDCD', 'DR2_030Z', 'WTDRD1', 'WTDR2D', 'DR2IGRMS', 'DR2IKCAL', 'DR2ICARB', 'DR2ISUGR', 'DR2IFIBE', 'DR2IMOIS']].rename(columns={'DR2IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1IFDCD':'DR2IFDCD', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE'})\n",
    "iff_2_C['DR2ILINE'] = iff_2_C['DR2ILINE'] + 100 # combining two days of diet recalls, need unique DR Line items for ingredientization; add 100 to each line item for 2nd recalls for unique values\n",
    "iff_2_C['diet_day'] = 2\n",
    "iff_C = pd.concat([iff_1_C, iff_2_C])\n",
    "iff_C['diet_wts'] = iff_C['WTDR2D']\n",
    "iff_C = iff_C.drop(columns=['WTDRD1', 'WTDR2D'])\n",
    "food_desc_C.drop(columns='DRXFCSD', inplace=True)\n",
    "recall_1_C = pd.merge(food_desc_C, iff_C, on = 'DRXFDCD')\n",
    "recall_1_C_ = pd.merge(recall_1_C, demo_C, on = 'SEQN')\n",
    "recall_1_C_['CYCLE'] = '03_04'\n",
    "recall_1_C_['RIAGENDR'].replace({1 : 'Male', 2 : 'Female'}, inplace=True)\n",
    "recall_1_C_['RIDRETH1'].replace({1 : \"Mexican_American\", 2 : \"Other_Hispanic\", 3 : \"Non-Hispanic_White\", 4 : 'Non-Hispanic_Black', 5 : \"Other_Multi-Racial\"}, inplace=True)\n",
    "recall_1_C_['DMDBORN'].replace({1 : \"US\", 2 : \"Mexico\", 3 : \"Elsewhere\", 7 : 'Unknown'}, inplace=True)\n",
    "recall_1_C_['DR2_030Z'].replace({\n",
    "  1 : 'Breakfast',\n",
    "  2 : 'Lunch',\n",
    "  3 : 'Dinner',\n",
    "  4 : 'Dinner',\n",
    "  5 : 'Brunch',\n",
    "  6 : 'Snack',\n",
    "  7 : 'Drink',\n",
    "  8 : 'Infant feeding',\n",
    "  9 : 'Extended consumption',\n",
    "  10 : 'Breakfast',\n",
    "  11 : 'Breakfast',\n",
    "  12 : 'Lunch',\n",
    "  13 : 'Snack',\n",
    "  14 : 'Dinner',\n",
    "  15 : 'Snack',\n",
    "  16 : 'Snack',\n",
    "  17 : 'Snack',\n",
    "  18 : 'Snack',\n",
    "  19 : 'Drink',\n",
    "  91 : 'Unknown',\n",
    "  99 : 'Unknown'\n",
    "}, inplace=True)\n",
    "\n",
    "demo_D = demo_D[['SEQN', 'RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'RIDEXPRG', 'DMDBORN', 'INDFMPIR', 'DMDYRSUS', 'DMDEDUC3', 'DMDEDUC2', 'WTINT2YR', 'WTMEC2YR', 'SDMVPSU', 'SDMVSTRA']]\n",
    "iff_1_D = iff_1_D[['SEQN', 'DRDINT', 'DR1DRSTZ', 'DR1ILINE', 'DR1IFDCD', 'DR1_030Z', 'WTDRD1', 'WTDR2D', 'DR1IGRMS', 'DR1IKCAL', 'DR1ICARB', 'DR1ISUGR', 'DR1IFIBE', 'DR1IMOIS']].rename(columns={'DR1IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE', 'DR1IMOIS':'DR2IMOIS'})\n",
    "iff_1_D['diet_day'] = 1\n",
    "iff_2_D = iff_2_D[['SEQN', 'DRDINT', 'DR2DRSTZ', 'DR2ILINE', 'DR2IFDCD', 'DR2_030Z', 'WTDRD1', 'WTDR2D', 'DR2IGRMS', 'DR2IKCAL', 'DR2ICARB', 'DR2ISUGR', 'DR2IFIBE', 'DR2IMOIS']].rename(columns={'DR2IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1IFDCD':'DR2IFDCD', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE'})\n",
    "iff_2_D['DR2ILINE'] = iff_2_D['DR2ILINE'] + 100 # combining two days of diet recalls, need unique DR Line items for ingredientization; add 100 to each line item for 2nd recalls for unique values\n",
    "iff_2_D['diet_day'] = 2\n",
    "iff_D = pd.concat([iff_1_D, iff_2_D])\n",
    "iff_D['diet_wts'] = iff_D['WTDR2D']\n",
    "iff_D = iff_D.drop(columns=['WTDRD1', 'WTDR2D'])\n",
    "food_desc_D.drop(columns='DRXFCSD', inplace=True)\n",
    "recall_1_D = pd.merge(food_desc_D, iff_D, on = 'DRXFDCD')\n",
    "recall_1_D_ = pd.merge(recall_1_D, demo_D, on = 'SEQN')\n",
    "recall_1_D_['CYCLE'] = '05_06'\n",
    "recall_1_D_['RIAGENDR'].replace({1 : 'Male', 2 : 'Female'}, inplace=True)\n",
    "recall_1_D_['RIDRETH1'].replace({1 : \"Mexican_American\", 2 : \"Other_Hispanic\", 3 : \"Non-Hispanic_White\", 4 : 'Non-Hispanic_Black', 5 : \"Other_Multi-Racial\"}, inplace=True)\n",
    "recall_1_D_['DMDBORN'].replace({1 : \"US\", 2 : \"Mexico\", 3 : \"Elsewhere\", 7 : 'Unknown'}, inplace=True)\n",
    "recall_1_D_['DR2_030Z'].replace({\n",
    "  1 : 'Breakfast',\n",
    "  2 : 'Lunch',\n",
    "  3 : 'Dinner',\n",
    "  4 : 'Dinner',\n",
    "  5 : 'Brunch',\n",
    "  6 : 'Snack',\n",
    "  7 : 'Drink',\n",
    "  8 : 'Infant feeding',\n",
    "  9 : 'Extended consumption',\n",
    "  10 : 'Breakfast',\n",
    "  11 : 'Breakfast',\n",
    "  12 : 'Lunch',\n",
    "  13 : 'Snack',\n",
    "  14 : 'Dinner',\n",
    "  15 : 'Snack',\n",
    "  16 : 'Snack',\n",
    "  17 : 'Snack',\n",
    "  18 : 'Snack',\n",
    "  19 : 'Drink',\n",
    "  91 : 'Unknown',\n",
    "  99 : 'Unknown'\n",
    "}, inplace=True)\n",
    "\n",
    "demo_E = demo_E[['SEQN', 'RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'RIDEXPRG', 'DMDBORN2', 'INDFMPIR', 'DMDYRSUS', 'DMDEDUC3', 'DMDEDUC2', 'WTINT2YR', 'WTMEC2YR', 'SDMVPSU', 'SDMVSTRA']].rename(columns={'DMDBORN2':'DMDBORN'})\n",
    "iff_1_E = iff_1_E[['SEQN', 'DRDINT', 'DR1DRSTZ', 'DR1ILINE', 'DR1IFDCD', 'DR1_030Z', 'WTDRD1', 'WTDR2D', 'DR1IGRMS', 'DR1IKCAL', 'DR1ICARB', 'DR1ISUGR', 'DR1IFIBE', 'DR1IMOIS']].rename(columns={'DR1IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE', 'DR1IMOIS':'DR2IMOIS'})\n",
    "iff_1_E['diet_day'] = 1\n",
    "iff_2_E = iff_2_E[['SEQN', 'DRDINT', 'DR2DRSTZ', 'DR2ILINE', 'DR2IFDCD', 'DR2_030Z', 'WTDRD1', 'WTDR2D', 'DR2IGRMS', 'DR2IKCAL', 'DR2ICARB', 'DR2ISUGR', 'DR2IFIBE', 'DR2IMOIS']].rename(columns={'DR2IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1IFDCD':'DR2IFDCD', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE'})\n",
    "iff_2_E['DR2ILINE'] = iff_2_E['DR2ILINE'] + 100 # combining two days of diet recalls, need unique DR Line items for ingredientization; add 100 to each line item for 2nd recalls for unique values\n",
    "iff_2_E['diet_day'] = 2\n",
    "iff_E = pd.concat([iff_1_E, iff_2_E])\n",
    "iff_E['diet_wts'] = iff_E['WTDR2D']\n",
    "iff_E = iff_E.drop(columns=['WTDRD1', 'WTDR2D'])\n",
    "food_desc_E.drop(columns='DRXFCSD', inplace=True)\n",
    "recall_1_E = pd.merge(food_desc_E, iff_E, on = 'DRXFDCD')\n",
    "recall_1_E_ = pd.merge(recall_1_E, demo_E, on = 'SEQN')\n",
    "recall_1_E_['CYCLE'] = '07_08'\n",
    "recall_1_E_['RIAGENDR'].replace({1 : 'Male', 2 : 'Female'}, inplace=True)\n",
    "recall_1_E_['RIDRETH1'].replace({1 : \"Mexican_American\", 2 : \"Other_Hispanic\", 3 : \"Non-Hispanic_White\", 4 : 'Non-Hispanic_Black', 5 : \"Other_Multi-Racial\"}, inplace=True)\n",
    "recall_1_E_['DMDBORN'].replace({1 : \"US\", 2 : \"Mexico\", 4 : \"Other_Spanish_Speaking_Country\", 5 : 'Other_Non-Spanish_Speaking_Country', 7 : 'Unknown', 9 : 'Unknown'}, inplace=True)\n",
    "recall_1_E_['DR2_030Z'].replace({\n",
    "  1 : 'Breakfast',\n",
    "  2 : 'Lunch',\n",
    "  3 : 'Dinner',\n",
    "  5 : 'Brunch',\n",
    "  6 : 'Snack',\n",
    "  8 : 'Infant feeding',\n",
    "  9 : 'Extended consumption',\n",
    "  10 : 'Breakfast',\n",
    "  11 : 'Breakfast',\n",
    "  12 : 'Lunch',\n",
    "  13 : 'Snack',\n",
    "  14 : 'Dinner',\n",
    "  15 : 'Snack',\n",
    "  16 : 'Snack',\n",
    "  17 : 'Snack',\n",
    "  91 : 'Unknown',\n",
    "  99 : 'Unknown'\n",
    "}, inplace=True)\n",
    "\n",
    "demo_F = demo_F[['SEQN', 'RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'RIDEXPRG', 'DMDBORN2', 'INDFMPIR', 'DMDYRSUS', 'DMDEDUC3', 'DMDEDUC2', 'WTINT2YR', 'WTMEC2YR', 'SDMVPSU', 'SDMVSTRA']].rename(columns={'DMDBORN2':'DMDBORN'})\n",
    "iff_1_F = iff_1_F[['SEQN', 'DRDINT', 'DR1DRSTZ', 'DR1ILINE', 'DR1IFDCD', 'DR1_030Z', 'WTDRD1', 'WTDR2D', 'DR1IGRMS', 'DR1IKCAL', 'DR1ICARB', 'DR1ISUGR', 'DR1IFIBE', 'DR1IMOIS']].rename(columns={'DR1IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE', 'DR1IMOIS':'DR2IMOIS'})\n",
    "iff_1_F['diet_day'] = 1\n",
    "iff_2_F = iff_2_F[['SEQN', 'DRDINT', 'DR2DRSTZ', 'DR2ILINE', 'DR2IFDCD', 'DR2_030Z', 'WTDRD1', 'WTDR2D', 'DR2IGRMS', 'DR2IKCAL', 'DR2ICARB', 'DR2ISUGR', 'DR2IFIBE', 'DR2IMOIS']].rename(columns={'DR2IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1IFDCD':'DR2IFDCD', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE'})\n",
    "iff_2_F['DR2ILINE'] = iff_2_F['DR2ILINE'] + 100 # combining two days of diet recalls, need unique DR Line items for ingredientization; add 100 to each line item for 2nd recalls for unique values\n",
    "iff_2_F['diet_day'] = 2\n",
    "iff_F = pd.concat([iff_1_F, iff_2_F])\n",
    "iff_F['diet_wts'] = iff_F['WTDR2D']\n",
    "iff_F = iff_F.drop(columns=['WTDRD1', 'WTDR2D'])\n",
    "food_desc_F.drop(columns='DRXFCSD', inplace=True)\n",
    "recall_1_F = pd.merge(food_desc_F, iff_F, on = 'DRXFDCD')\n",
    "recall_1_F_ = pd.merge(recall_1_F, demo_F, on = 'SEQN')\n",
    "recall_1_F_['CYCLE'] = '09_10'\n",
    "recall_1_F_['RIAGENDR'].replace({1 : 'Male', 2 : 'Female'}, inplace=True)\n",
    "recall_1_F_['RIDRETH1'].replace({1 : \"Mexican_American\", 2 : \"Other_Hispanic\", 3 : \"Non-Hispanic_White\", 4 : 'Non-Hispanic_Black', 5 : \"Other_Multi-Racial\"}, inplace=True)\n",
    "recall_1_F_['DMDBORN'].replace({1 : \"US\", 2 : \"Mexico\", 4 : \"Other_Spanish_Speaking_Country\", 5 : 'Other_Non-Spanish_Speaking_Country', 7 : 'Unknown', 9 : 'Unknown'}, inplace=True)\n",
    "recall_1_F_['DR2_030Z'].replace({\n",
    "  1 : 'Breakfast',\n",
    "  2 : 'Lunch',\n",
    "  3 : 'Dinner',\n",
    "  4 : 'Dinner',\n",
    "  5 : 'Brunch',\n",
    "  6 : 'Snack',\n",
    "  7 : 'Drink',\n",
    "  8 : 'Infant feeding',\n",
    "  9 : 'Extended consumption',\n",
    "  10 : 'Breakfast',\n",
    "  11 : 'Breakfast',\n",
    "  12 : 'Lunch',\n",
    "  13 : 'Snack',\n",
    "  14 : 'Dinner',\n",
    "  15 : 'Snack',\n",
    "  16 : 'Snack',\n",
    "  17 : 'Snack',\n",
    "  18 : 'Snack',\n",
    "  19 : 'Drink',\n",
    "  91 : 'Unknown',\n",
    "  99 : 'Unknown'\n",
    "}, inplace=True)\n",
    "\n",
    "demo_G = demo_G[['SEQN', 'RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'RIDEXPRG', 'DMDBORN4', 'INDFMPIR', 'DMDYRSUS', 'DMDEDUC3', 'DMDEDUC2', 'WTINT2YR', 'WTMEC2YR', 'SDMVPSU', 'SDMVSTRA']].rename(columns={'DMDBORN4':'DMDBORN'})\n",
    "iff_1_G = iff_1_G[['SEQN', 'DRDINT', 'DR1DRSTZ', 'DR1ILINE', 'DR1IFDCD', 'DR1_030Z', 'WTDRD1', 'WTDR2D', 'DR1IGRMS', 'DR1IKCAL', 'DR1ICARB', 'DR1ISUGR', 'DR1IFIBE', 'DR1IMOIS']].rename(columns={'DR1IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE', 'DR1IMOIS':'DR2IMOIS'})\n",
    "iff_1_G['diet_day'] = 1\n",
    "iff_2_G = iff_2_G[['SEQN', 'DRDINT', 'DR2DRSTZ', 'DR2ILINE', 'DR2IFDCD', 'DR2_030Z', 'WTDRD1', 'WTDR2D', 'DR2IGRMS', 'DR2IKCAL', 'DR2ICARB', 'DR2ISUGR', 'DR2IFIBE', 'DR2IMOIS']].rename(columns={'DR2IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1IFDCD':'DR2IFDCD', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE'})\n",
    "iff_2_G['DR2ILINE'] = iff_2_G['DR2ILINE'] + 100 # combining two days of diet recalls, need unique DR Line items for ingredientization; add 100 to each line item for 2nd recalls for unique values\n",
    "iff_2_G['diet_day'] = 2\n",
    "iff_G = pd.concat([iff_1_G, iff_2_G])\n",
    "iff_G['diet_wts'] = iff_G['WTDR2D']\n",
    "iff_G = iff_G.drop(columns=['WTDRD1', 'WTDR2D'])\n",
    "food_desc_G.drop(columns='DRXFCSD', inplace=True)\n",
    "recall_1_G = pd.merge(food_desc_G, iff_G, on = 'DRXFDCD')\n",
    "recall_1_G_ = pd.merge(recall_1_G, demo_G, on = 'SEQN')\n",
    "recall_1_G_['CYCLE'] = '11_12'\n",
    "recall_1_G_['RIAGENDR'].replace({1 : 'Male', 2 : 'Female'}, inplace=True)\n",
    "recall_1_G_['RIDRETH1'].replace({1 : \"Mexican_American\", 2 : \"Other_Hispanic\", 3 : \"Non-Hispanic_White\", 4 : 'Non-Hispanic_Black', 5 : \"Other_Multi-Racial\"}, inplace=True)\n",
    "recall_1_G_['DMDBORN'].replace({1 : \"US\", 2 : \"Elsewhere\", 77 : 'Unknown', 99 : 'Unknown'}, inplace=True)\n",
    "recall_1_G_['DR2_030Z'].replace({\n",
    "  1 : 'Breakfast',\n",
    "  2 : 'Lunch',\n",
    "  3 : 'Dinner',\n",
    "  4 : 'Dinner',\n",
    "  5 : 'Brunch',\n",
    "  6 : 'Snack',\n",
    "  7 : 'Drink',\n",
    "  8 : 'Infant feeding',\n",
    "  9 : 'Extended consumption',\n",
    "  10 : 'Breakfast',\n",
    "  11 : 'Breakfast',\n",
    "  12 : 'Lunch',\n",
    "  13 : 'Snack',\n",
    "  14 : 'Dinner',\n",
    "  15 : 'Snack',\n",
    "  16 : 'Snack',\n",
    "  17 : 'Snack',\n",
    "  18 : 'Snack',\n",
    "  19 : 'Drink',\n",
    "  91 : 'Unknown',\n",
    "  99 : 'Unknown'\n",
    "}, inplace=True)\n",
    "\n",
    "demo_H = demo_H[['SEQN', 'RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'RIDEXPRG', 'DMDBORN4', 'INDFMPIR', 'DMDYRSUS', 'DMDEDUC3', 'DMDEDUC2', 'WTINT2YR', 'WTMEC2YR', 'SDMVPSU', 'SDMVSTRA']].rename(columns={'DMDBORN4':'DMDBORN'})\n",
    "iff_1_H = iff_1_H[['SEQN', 'DRDINT', 'DR1DRSTZ', 'DR1ILINE', 'DR1IFDCD', 'DR1_030Z', 'WTDRD1', 'WTDR2D', 'DR1IGRMS', 'DR1IKCAL', 'DR1ICARB', 'DR1ISUGR', 'DR1IFIBE', 'DR1IMOIS']].rename(columns={'DR1IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE', 'DR1IMOIS':'DR2IMOIS'})\n",
    "iff_1_H['diet_day'] = 1\n",
    "iff_2_H = iff_2_H[['SEQN', 'DRDINT', 'DR2DRSTZ', 'DR2ILINE', 'DR2IFDCD', 'DR2_030Z', 'WTDRD1', 'WTDR2D', 'DR2IGRMS', 'DR2IKCAL', 'DR2ICARB', 'DR2ISUGR', 'DR2IFIBE', 'DR2IMOIS']].rename(columns={'DR2IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1IFDCD':'DR2IFDCD', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE'})\n",
    "iff_2_H['DR2ILINE'] = iff_2_H['DR2ILINE'] + 100 # combining two days of diet recalls, need unique DR Line items for ingredientization; add 100 to each line item for 2nd recalls for unique values\n",
    "iff_2_H['diet_day'] = 2\n",
    "iff_H = pd.concat([iff_1_H, iff_2_H])\n",
    "iff_H['diet_wts'] = iff_H['WTDR2D']\n",
    "iff_H = iff_H.drop(columns=['WTDRD1', 'WTDR2D'])\n",
    "food_desc_H.drop(columns='DRXFCSD', inplace=True)\n",
    "recall_1_H = pd.merge(food_desc_H, iff_H, on = 'DRXFDCD')\n",
    "recall_1_H_ = pd.merge(recall_1_H, demo_H, on = 'SEQN')\n",
    "recall_1_H_['CYCLE'] = '13_14'\n",
    "recall_1_H_['RIAGENDR'].replace({1 : 'Male', 2 : 'Female'}, inplace=True)\n",
    "recall_1_H_['RIDRETH1'].replace({1 : \"Mexican_American\", 2 : \"Other_Hispanic\", 3 : \"Non-Hispanic_White\", 4 : 'Non-Hispanic_Black', 5 : \"Other_Multi-Racial\"}, inplace=True)\n",
    "recall_1_H_['DMDBORN'].replace({1 : \"US\", 2 : \"Elsewhere\", 77 : 'Unknown', 99 : 'Unknown'}, inplace=True)\n",
    "recall_1_H_['DR2_030Z'].replace({\n",
    "  1 : 'Breakfast',\n",
    "  2 : 'Lunch',\n",
    "  3 : 'Dinner',\n",
    "  4 : 'Dinner',\n",
    "  5 : 'Brunch',\n",
    "  6 : 'Snack',\n",
    "  7 : 'Drink',\n",
    "  8 : 'Infant feeding',\n",
    "  9 : 'Extended consumption',\n",
    "  10 : 'Breakfast',\n",
    "  11 : 'Breakfast',\n",
    "  12 : 'Lunch',\n",
    "  13 : 'Snack',\n",
    "  14 : 'Dinner',\n",
    "  15 : 'Snack',\n",
    "  16 : 'Snack',\n",
    "  17 : 'Snack',\n",
    "  18 : 'Snack',\n",
    "  19 : 'Drink',\n",
    "  91 : 'Unknown',\n",
    "  99 : 'Unknown'\n",
    "}, inplace=True)\n",
    "\n",
    "demo_I = demo_I[['SEQN', 'RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'RIDEXPRG', 'DMDBORN4', 'INDFMPIR', 'DMDYRSUS', 'DMDEDUC3', 'DMDEDUC2', 'WTINT2YR', 'WTMEC2YR', 'SDMVPSU', 'SDMVSTRA']].rename(columns={'DMDBORN4':'DMDBORN'})\n",
    "iff_1_I = iff_1_I[['SEQN', 'DRDINT', 'DR1DRSTZ', 'DR1ILINE', 'DR1IFDCD', 'DR1_030Z', 'WTDRD1', 'WTDR2D', 'DR1IGRMS', 'DR1IKCAL', 'DR1ICARB', 'DR1ISUGR', 'DR1IFIBE', 'DR1IMOIS']].rename(columns={'DR1IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE', 'DR1IMOIS':'DR2IMOIS'})\n",
    "iff_1_I['diet_day'] = 1\n",
    "iff_2_I = iff_2_I[['SEQN', 'DRDINT', 'DR2DRSTZ', 'DR2ILINE', 'DR2IFDCD', 'DR2_030Z', 'WTDRD1', 'WTDR2D', 'DR2IGRMS', 'DR2IKCAL', 'DR2ICARB', 'DR2ISUGR', 'DR2IFIBE', 'DR2IMOIS']].rename(columns={'DR2IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1IFDCD':'DR2IFDCD', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE'})\n",
    "iff_2_I['DR2ILINE'] = iff_2_I['DR2ILINE'] + 100 # combining two days of diet recalls, need unique DR Line items for ingredientization; add 100 to each line item for 2nd recalls for unique values\n",
    "iff_2_I['diet_day'] = 2\n",
    "iff_I = pd.concat([iff_1_I, iff_2_I])\n",
    "iff_I['diet_wts'] = iff_I['WTDR2D']\n",
    "iff_I = iff_I.drop(columns=['WTDRD1', 'WTDR2D'])\n",
    "food_desc_I.drop(columns='DRXFCSD', inplace=True)\n",
    "recall_1_I = pd.merge(food_desc_I, iff_I, on = 'DRXFDCD')\n",
    "recall_1_I_ = pd.merge(recall_1_I, demo_I, on = 'SEQN')\n",
    "recall_1_I_['CYCLE'] = '15_16'\n",
    "recall_1_I_['RIAGENDR'].replace({1 : 'Male', 2 : 'Female'}, inplace=True)\n",
    "recall_1_I_['RIDRETH1'].replace({1 : \"Mexican_American\", 2 : \"Other_Hispanic\", 3 : \"Non-Hispanic_White\", 4 : 'Non-Hispanic_Black', 5 : \"Other_Multi-Racial\"}, inplace=True)\n",
    "recall_1_I_['DMDBORN'].replace({1 : \"US\", 2 : \"Elsewhere\", 77 : 'Unknown', 99 : 'Unknown'}, inplace=True)\n",
    "recall_1_I_['DR2_030Z'].replace({\n",
    "  1 : 'Breakfast',\n",
    "  2 : 'Lunch',\n",
    "  3 : 'Dinner',\n",
    "  4 : 'Dinner',\n",
    "  5 : 'Brunch',\n",
    "  6 : 'Snack',\n",
    "  7 : 'Drink',\n",
    "  8 : 'Infant feeding',\n",
    "  9 : 'Extended consumption',\n",
    "  10 : 'Breakfast',\n",
    "  11 : 'Breakfast',\n",
    "  12 : 'Lunch',\n",
    "  13 : 'Snack',\n",
    "  14 : 'Dinner',\n",
    "  15 : 'Snack',\n",
    "  16 : 'Snack',\n",
    "  17 : 'Snack',\n",
    "  18 : 'Snack',\n",
    "  19 : 'Drink',\n",
    "  91 : 'Unknown',\n",
    "  99 : 'Unknown'\n",
    "}, inplace=True)\n",
    "\n",
    "demo_P = demo_P[['SEQN', 'RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'RIDEXPRG', 'DMDBORN4', 'INDFMPIR', 'DMDYRUSZ', 'DMDEDUC2', 'WTINTPRP', 'WTMECPRP', 'SDMVPSU', 'SDMVSTRA']].rename(columns={'DMDBORN4':'DMDBORN', 'DMDYRUSZ': 'DMDYRSUS'})\n",
    "demo_P['DMDEDUC3'] = float('nan') # no education data collected for persons under 20 y/o. Generating NAs for merging with earlier cycles\n",
    "iff_1_P = iff_1_P[['SEQN', 'DRDINT', 'DR1DRSTZ', 'DR1ILINE', 'DR1IFDCD', 'DR1_030Z', 'WTDRD1PP', 'WTDR2DPP', 'DR1IGRMS', 'DR1IKCAL', 'DR1ICARB', 'DR1ISUGR', 'DR1IFIBE', 'DR1IMOIS']].rename(columns={'DR1IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1_030Z':'DR2_030Z', 'WTDRD1PP':'WTDRD1', 'WTDR2DPP':'WTDR2D', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE', 'DR1IMOIS':'DR2IMOIS'})\n",
    "iff_1_P['diet_day'] = 1\n",
    "iff_2_P = iff_2_P[['SEQN', 'DRDINT', 'DR2DRSTZ', 'DR2ILINE', 'DR2IFDCD', 'DR2_030Z', 'WTDRD1PP', 'WTDR2DPP', 'DR2IGRMS', 'DR2IKCAL', 'DR2ICARB', 'DR2ISUGR', 'DR2IFIBE', 'DR2IMOIS']].rename(columns={'DR2IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1IFDCD':'DR2IFDCD', 'DR1_030Z':'DR2_030Z', 'WTDRD1PP':'WTDRD1', 'WTDR2DPP':'WTDR2D', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE'})\n",
    "iff_2_P['DR2ILINE'] = iff_2_P['DR2ILINE'] + 100 # combining two days of diet recalls, need unique DR Line items for ingredientization; add 100 to each line item for 2nd recalls for unique values\n",
    "iff_2_P['diet_day'] = 2\n",
    "iff_P = pd.concat([iff_1_P, iff_2_P])\n",
    "iff_P['diet_wts'] = iff_P['WTDR2D']\n",
    "iff_P = iff_P.drop(columns=['WTDRD1', 'WTDR2D'])\n",
    "food_desc_P.drop(columns='DRXFCSD', inplace=True)\n",
    "recall_1_P = pd.merge(food_desc_P, iff_P, on = 'DRXFDCD')\n",
    "recall_1_P_ = pd.merge(recall_1_P, demo_P, on = 'SEQN')\n",
    "recall_1_P_['CYCLE'] = '17_20'\n",
    "recall_1_P_['RIAGENDR'].replace({1 : 'Male', 2 : 'Female'}, inplace=True)\n",
    "recall_1_P_['RIDRETH1'].replace({1 : \"Mexican_American\", 2 : \"Other_Hispanic\", 3 : \"Non-Hispanic_White\", 4 : 'Non-Hispanic_Black', 5 : \"Other_Multi-Racial\"}, inplace=True)\n",
    "recall_1_P_['DMDBORN'].replace({1 : \"US\", 2 : \"Elsewhere\", 77 : 'Unknown', 99 : 'Unknown'}, inplace=True)\n",
    "recall_1_P_['DR2_030Z'].replace({\n",
    "  1 : 'Breakfast',\n",
    "  2 : 'Lunch',\n",
    "  3 : 'Dinner',\n",
    "  4 : 'Dinner',\n",
    "  5 : 'Brunch',\n",
    "  6 : 'Snack',\n",
    "  7 : 'Drink',\n",
    "  8 : 'Infant feeding',\n",
    "  9 : 'Extended consumption',\n",
    "  10 : 'Breakfast',\n",
    "  11 : 'Breakfast',\n",
    "  12 : 'Lunch',\n",
    "  13 : 'Snack',\n",
    "  14 : 'Dinner',\n",
    "  15 : 'Snack',\n",
    "  16 : 'Snack',\n",
    "  17 : 'Snack',\n",
    "  18 : 'Snack',\n",
    "  19 : 'Drink',\n",
    "  91 : 'Unknown',\n",
    "  99 : 'Unknown'\n",
    "}, inplace=True)\n",
    "\n",
    "demo_L = demo_L[['SEQN', 'RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'RIDEXPRG', 'DMDBORN4', 'INDFMPIR', 'DMDYRUSR', 'DMDEDUC2', 'WTINT2YR', 'WTMEC2YR', 'SDMVPSU', 'SDMVSTRA']].rename(columns={'DMDBORN4':'DMDBORN', 'DMDYRUSR': 'DMDYRSUS'})\n",
    "demo_L['DMDEDUC3'] = float('nan') # no education data collected for persons under 20 y/o. Generating NAs for merging with earlier cycles\n",
    "iff_1_L = iff_1_L[['SEQN', 'DRDINT', 'DR1DRSTZ', 'DR1ILINE', 'DR1IFDCD', 'DR1_030Z', 'WTDRD1', 'WTDR2D', 'DR1IGRMS', 'DR1IKCAL', 'DR1ICARB', 'DR1ISUGR', 'DR1IFIBE', 'DR1IMOIS']].rename(columns={'DR1IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE', 'DR1IMOIS':'DR2IMOIS'})\n",
    "iff_1_L['diet_day'] = 1\n",
    "iff_2_L = iff_2_L[['SEQN', 'DRDINT', 'DR2DRSTZ', 'DR2ILINE', 'DR2IFDCD', 'DR2_030Z', 'WTDRD1', 'WTDR2D', 'DR2IGRMS', 'DR2IKCAL', 'DR2ICARB', 'DR2ISUGR', 'DR2IFIBE', 'DR2IMOIS']].rename(columns={'DR2IFDCD':'DRXFDCD', 'DR1DRSTZ':'DR2DRSTZ', 'DR1ILINE':'DR2ILINE', 'DR1IFDCD':'DR2IFDCD', 'DR1_030Z':'DR2_030Z', 'DR1IGRMS':'DR2IGRMS', 'DR1IKCAL':'DR2IKCAL', 'DR1ICARB':'DR2ICARB', 'DR1ISUGR':'DR2ISUGR', 'DR1IFIBE':'DR2IFIBE'})\n",
    "iff_2_L['DR2ILINE'] = iff_2_L['DR2ILINE'] + 100 # combining two days of diet recalls, need unique DR Line items for ingredientization; add 100 to each line item for 2nd recalls for unique values\n",
    "iff_2_L['diet_day'] = 2\n",
    "iff_L = pd.concat([iff_1_L, iff_2_L])\n",
    "iff_L['diet_wts'] = iff_L['WTDR2D']\n",
    "iff_L = iff_L.drop(columns=['WTDRD1', 'WTDR2D'])\n",
    "food_desc_L.drop(columns='DRXFCSD', inplace=True)\n",
    "recall_1_L = pd.merge(food_desc_L, iff_L, on = 'DRXFDCD')\n",
    "recall_1_L_ = pd.merge(recall_1_L, demo_L, on = 'SEQN')\n",
    "recall_1_L_['CYCLE'] = '21_22'\n",
    "recall_1_L_['RIAGENDR'].replace({1 : 'Male', 2 : 'Female'}, inplace=True)\n",
    "recall_1_L_['RIDRETH1'].replace({1 : \"Mexican_American\", 2 : \"Other_Hispanic\", 3 : \"Non-Hispanic_White\", 4 : 'Non-Hispanic_Black', 5 : \"Other_Multi-Racial\"}, inplace=True)\n",
    "recall_1_L_['DMDBORN'].replace({1 : \"US\", 2 : \"Elsewhere\", 77 : 'Unknown', 99 : 'Unknown'}, inplace=True)\n",
    "recall_1_L_['DR2_030Z'].replace({\n",
    "  1 : 'Breakfast',\n",
    "  2 : 'Lunch',\n",
    "  3 : 'Dinner',\n",
    "  4 : 'Dinner',\n",
    "  5 : 'Brunch',\n",
    "  6 : 'Snack',\n",
    "  7 : 'Drink',\n",
    "  8 : 'Infant feeding',\n",
    "  9 : 'Extended consumption',\n",
    "  10 : 'Breakfast',\n",
    "  11 : 'Breakfast',\n",
    "  12 : 'Lunch',\n",
    "  13 : 'Snack',\n",
    "  14 : 'Dinner',\n",
    "  15 : 'Snack',\n",
    "  16 : 'Snack',\n",
    "  17 : 'Snack',\n",
    "  18 : 'Snack',\n",
    "  19 : 'Drink',\n",
    "  91 : 'Unknown',\n",
    "  99 : 'Unknown'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36148aef-ab20-4a4f-b1e5-057855dbd7c0",
   "metadata": {},
   "source": [
    "### Combine all cycles into a single dataframe and apply exclusion criteria (Two 24-hr recalls, passing quality control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ecd1b9a-76f0-4433-bd7a-c871f765d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "WWEIA_ALL = pd.concat([recall_1_C_, recall_1_D_, recall_1_E_, recall_1_F_, recall_1_G_, recall_1_H_, recall_1_I_, recall_1_P_, recall_1_L_])\n",
    "\n",
    "# remove individuals with only one 24-hr recall\n",
    "WWEIA_ALL = WWEIA_ALL[WWEIA_ALL['DRDINT']==2]\n",
    "\n",
    "# remove individuals with diet data not passing quality control\n",
    "WWEIA_ALL = WWEIA_ALL[WWEIA_ALL['DR2DRSTZ']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533cdea3-f9a3-4489-9d9c-94c2b8db048f",
   "metadata": {},
   "source": [
    "### Cross walk food codes and descriptions to harmonize data across cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8534683-69d7-4f1e-b8e2-4a6cf5cc8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the FNDDS cross-walks to harmonize foodcodes\n",
    "# apply, combine for each cycle to correctly crosswalk codes\n",
    "xwalk_FG = pd.read_csv('../../data/00/fndds_crosswalk/fndds_0910_1112_crosswalk.csv')\n",
    "xwalk_GH = pd.read_csv('../../data/00/fndds_crosswalk/fndds_1112_1314_crosswalk.csv')\n",
    "xwalk_HI = pd.read_csv('../../data/00/fndds_crosswalk/fndds_1314_1516_crosswalk.csv')\n",
    "xwalk_IJ = pd.read_csv('../../data/00/fndds_crosswalk/fndds_1516_1718_crosswalk.csv')\n",
    "xwalk_JP = pd.read_csv('../../data/00/fndds_crosswalk/fndds_1718_1920_crosswalk.csv')\n",
    "xwalk_PL = pd.read_csv('../../data/00/fndds_crosswalk/fndds_1920_2123_crosswalk.csv')\n",
    "\n",
    "# combine crosswalk cycles\n",
    "xwalk_all = pd.concat([xwalk_PL, xwalk_JP, xwalk_IJ, xwalk_HI, xwalk_GH, xwalk_FG])\n",
    "\n",
    "# drop_duplicates (takes most recent change)\n",
    "xwalk_all.drop_duplicates(subset='DRXFDCD', inplace=True)\n",
    "\n",
    "# change to int for merging\n",
    "xwalk_all['foodcode'] = xwalk_all['foodcode'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63cf3e31-7c94-4e2b-baa0-274f4187a5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 9635 codes, 13327 descriptions\n",
      "Harmonized: 6896 codes, 6896 descriptions\n",
      "\n",
      "Descriptions by cycle:\n",
      "effective_cycle\n",
      "03_04     152\n",
      "05_06      87\n",
      "07_08     117\n",
      "09_10     233\n",
      "11_12     257\n",
      "13_14     463\n",
      "15_16     413\n",
      "17_20     837\n",
      "21_22    4337\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge and handle the CYCLE column conflict\n",
    "merged_with_cycles = WWEIA_ALL.merge(\n",
    "    xwalk_all[['DRXFDCD', 'foodcode', 'food_description', 'CYCLE']], \n",
    "    on='DRXFDCD', \n",
    "    how='left',\n",
    "    suffixes=('_original', '_update')  # This will create CYCLE_original and CYCLE_update\n",
    ")\n",
    "\n",
    "# For records that were updated, use the update cycle; for others, use original cycle\n",
    "merged_with_cycles['effective_cycle'] = merged_with_cycles['CYCLE_update'].fillna(merged_with_cycles['CYCLE_original'])\n",
    "\n",
    "# Update the food codes and descriptions where matches exist\n",
    "merged_with_cycles['DRXFDCD_final'] = merged_with_cycles['foodcode'].fillna(merged_with_cycles['DRXFDCD'])\n",
    "merged_with_cycles['DRXFCLD_final'] = merged_with_cycles['food_description'].fillna(merged_with_cycles['DRXFCLD'])\n",
    "\n",
    "# Get the most recent description for each food code\n",
    "most_recent_descriptions = (merged_with_cycles\n",
    "                           .sort_values('effective_cycle', ascending=False)\n",
    "                           .groupby('DRXFDCD_final')\n",
    "                           .agg({\n",
    "                               'DRXFCLD_final': 'first',  # Most recent description\n",
    "                               'effective_cycle': 'first'  # The cycle it came from\n",
    "                           })\n",
    "                           .reset_index())\n",
    "\n",
    "# Create your final harmonized dataset\n",
    "harmonized_codes = most_recent_descriptions.rename(columns={\n",
    "    'DRXFDCD_final': 'DRXFDCD',\n",
    "    'DRXFCLD_final': 'DRXFCLD'\n",
    "})[['DRXFDCD', 'DRXFCLD']]\n",
    "\n",
    "# Check the results\n",
    "print(f\"Original: {WWEIA_ALL['DRXFDCD'].nunique()} codes, {WWEIA_ALL['DRXFCLD'].nunique()} descriptions\")\n",
    "print(f\"Harmonized: {harmonized_codes['DRXFDCD'].nunique()} codes, {harmonized_codes['DRXFCLD'].nunique()} descriptions\")\n",
    "\n",
    "# Show which cycles contributed\n",
    "cycle_contributions = most_recent_descriptions['effective_cycle'].value_counts().sort_index()\n",
    "print(f\"\\nDescriptions by cycle:\")\n",
    "print(cycle_contributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ecccee4-45de-4c7d-8327-45d8c55b8902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original WWEIA_ALL shape: (2124046, 33)\n",
      "Harmonized WWEIA_ALL shape: (2124046, 33)\n",
      "Original unique descriptions: 13327\n",
      "Harmonized unique descriptions: 6871\n",
      "Records in original: 2124046\n",
      "Records in harmonized: 2124046\n",
      "Warning: 236505 records have missing descriptions after harmonization\n",
      "Problematic codes: [41601080. 57807010. 67104040. 76407000. 94000000. 11421000. 31103000.\n",
      " 71802010. 92570100. 32104950.]...\n"
     ]
    }
   ],
   "source": [
    "# Apply the harmonized food codes and descriptions to your full dataset\n",
    "WWEIA_ALL_harmonized = WWEIA_ALL.merge(\n",
    "    harmonized_codes[['DRXFDCD', 'DRXFCLD']], \n",
    "    on='DRXFDCD', \n",
    "    how='left',\n",
    "    suffixes=('_old', '_harmonized')\n",
    ")\n",
    "\n",
    "# Replace the old food descriptions with harmonized ones\n",
    "WWEIA_ALL_harmonized['DRXFCLD'] = WWEIA_ALL_harmonized['DRXFCLD_harmonized']\n",
    "\n",
    "# Drop the temporary columns\n",
    "WWEIA_ALL_harmonized = WWEIA_ALL_harmonized.drop(['DRXFCLD_old', 'DRXFCLD_harmonized'], axis=1)\n",
    "\n",
    "# Check the results\n",
    "print(f\"Original WWEIA_ALL shape: {WWEIA_ALL.shape}\")\n",
    "print(f\"Harmonized WWEIA_ALL shape: {WWEIA_ALL_harmonized.shape}\")\n",
    "print(f\"Original unique descriptions: {WWEIA_ALL['DRXFCLD'].nunique()}\")\n",
    "print(f\"Harmonized unique descriptions: {WWEIA_ALL_harmonized['DRXFCLD'].nunique()}\")\n",
    "\n",
    "# Verify no data was lost\n",
    "print(f\"Records in original: {len(WWEIA_ALL)}\")\n",
    "print(f\"Records in harmonized: {len(WWEIA_ALL_harmonized)}\")\n",
    "\n",
    "# Check for any unmatched food codes (should be minimal since we used left join in harmonization)\n",
    "unmatched = WWEIA_ALL_harmonized['DRXFCLD'].isna().sum()\n",
    "if unmatched > 0:\n",
    "    print(f\"Warning: {unmatched} records have missing descriptions after harmonization\")\n",
    "    # Show which codes are problematic\n",
    "    problem_codes = WWEIA_ALL_harmonized[WWEIA_ALL_harmonized['DRXFCLD'].isna()]['DRXFDCD'].unique()\n",
    "    print(f\"Problematic codes: {problem_codes[:10]}...\")  # Show first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5903fd3e-578f-4f9c-a7cd-ea98dce6687e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing food codes: 2764\n",
      "Codes in original WWEIA_ALL: 9635\n",
      "Codes in harmonized lookup: 6896\n",
      "Codes missing from harmonization: 2764\n",
      "\n",
      "Examples of missing codes:\n",
      "           DRXFDCD                                            DRXFCLD  CYCLE\n",
      "1511    41601080.0                                    Pinto bean soup  03_04\n",
      "1520    57807010.0  Whole wheat cereal with apples, baby food, dry...  03_04\n",
      "1527    67104040.0       Applesauce with bananas, baby food, strained  03_04\n",
      "1544    76407000.0  Mixed vegetables, garden vegetables, baby food...  03_04\n",
      "1549    94000000.0                             Water as an ingredient  03_04\n",
      "1767    11421000.0  Yogurt, vanilla, lemon, or coffee flavor, whol...  03_04\n",
      "1774    31103000.0                                 Egg, whole, boiled  03_04\n",
      "1790    71802010.0                           Macaroni and potato soup  03_04\n",
      "3566    92570100.0            Fluid replacement, electrolyte solution  03_04\n",
      "3574    32104950.0  Egg omelet or scrambled egg, fat not added in ...  03_04\n",
      "737     94000000.0                             Water as an ingredient  05_06\n",
      "1371    92570100.0            Fluid replacement, electrolyte solution  05_06\n",
      "5024    31103000.0                                 Egg, whole, boiled  05_06\n",
      "5152    32104950.0  Egg omelet or scrambled egg, fat not added in ...  05_06\n",
      "8446    71802010.0                           Macaroni and potato soup  05_06\n",
      "15578   11421000.0  Yogurt, vanilla, lemon, or coffee flavor, whol...  05_06\n",
      "29824   41601080.0                                    Pinto bean soup  05_06\n",
      "64222   57807010.0  Whole wheat cereal with apples, baby food, dry...  05_06\n",
      "72513   67104040.0       Applesauce with bananas, baby food, strained  05_06\n",
      "1840    94000000.0                             Water as an ingredient  07_08\n",
      "3384    31103000.0                                 Egg, whole, boiled  07_08\n",
      "4919    32104950.0  Egg omelet or scrambled egg, fat not added in ...  07_08\n",
      "13214   11421000.0  Yogurt, vanilla, lemon, or coffee flavor, whol...  07_08\n",
      "16016   92570100.0            Fluid replacement, electrolyte solution  07_08\n",
      "99014   41601080.0                                    Pinto bean soup  07_08\n",
      "196865  67104040.0       Applesauce with bananas, baby food, strained  07_08\n",
      "197310  76407000.0  Mixed vegetables, garden vegetables, baby food...  07_08\n",
      "825     92570100.0            Fluid replacement, electrolyte solution  09_10\n",
      "827     94000000.0                             Water as an ingredient  09_10\n",
      "3560    31103000.0                                 Egg, whole, boiled  09_10\n",
      "7703    32104950.0  Egg omelet or scrambled egg, fat not added in ...  09_10\n",
      "11339   11421000.0  Yogurt, vanilla, lemon, or coffee flavor, whol...  09_10\n",
      "60156   67104040.0       Applesauce with bananas, baby food, strained  09_10\n",
      "212843  57807010.0  Whole wheat cereal with apples, baby food, dry...  09_10\n",
      "213915  76407000.0  Mixed vegetables, garden vegetables, baby food...  09_10\n",
      "222205  41601080.0                                    Pinto bean soup  09_10\n",
      "4792    11421000.0  Yogurt, vanilla, lemon, or coffee flavor, whol...  11_12\n",
      "163582  57807010.0  Whole wheat cereal with apples, baby food, dry...  11_12\n",
      "173746  67104040.0       Applesauce with bananas, baby food, strained  11_12\n",
      "173793  76407000.0  Mixed vegetables, garden vegetables, baby food...  11_12\n",
      "2419    11421000.0                        Yogurt, vanilla, whole milk  13_14\n",
      "174057  67104040.0       Applesauce with bananas, baby food, strained  13_14\n",
      "174683  76407000.0  Mixed vegetables, garden vegetables, baby food...  13_14\n",
      "175533  57807010.0  Whole wheat cereal with apples, baby food, dry...  13_14\n",
      "49040   67104040.0       Applesauce with bananas, baby food, strained  15_16\n",
      "125216  57807010.0  Whole wheat cereal with apples, baby food, dry...  15_16\n",
      "10895   41601080.0  Pinto bean soup, home recipe, canned or ready-...  17_20\n",
      "19204   67104040.0       Applesauce with bananas, baby food, strained  17_20\n",
      "214776  76407000.0  Mixed vegetables, garden vegetables, baby food...  17_20\n",
      "215807  57807010.0  Whole wheat cereal with apples, baby food, dry...  17_20\n"
     ]
    }
   ],
   "source": [
    "# Find the missing codes\n",
    "missing_codes = WWEIA_ALL_harmonized[WWEIA_ALL_harmonized['DRXFCLD'].isna()]['DRXFDCD'].unique()\n",
    "print(f\"Number of missing food codes: {len(missing_codes)}\")\n",
    "\n",
    "# Check if these codes exist in your original harmonized_df\n",
    "codes_in_harmonized = set(harmonized_codes['DRXFDCD'])\n",
    "codes_in_original = set(WWEIA_ALL['DRXFDCD'])\n",
    "missing_from_harmonization = codes_in_original - codes_in_harmonized\n",
    "\n",
    "print(f\"Codes in original WWEIA_ALL: {len(codes_in_original)}\")\n",
    "print(f\"Codes in harmonized lookup: {len(codes_in_harmonized)}\")\n",
    "print(f\"Codes missing from harmonization: {len(missing_from_harmonization)}\")\n",
    "\n",
    "# See some examples of missing codes and their original descriptions\n",
    "missing_examples = WWEIA_ALL[WWEIA_ALL['DRXFDCD'].isin(list(missing_codes)[:10])][['DRXFDCD', 'DRXFCLD', 'CYCLE']].drop_duplicates()\n",
    "print(\"\\nExamples of missing codes:\")\n",
    "print(missing_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c66084a-0d5e-41c4-b6ea-dfc46c6dceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing codes to add: 2764\n",
      "Complete harmonized lookup: 9660 codes\n",
      "Should equal original unique codes: 9635\n",
      "Still missing after adding: 0 codes\n"
     ]
    }
   ],
   "source": [
    "# Create harmonized entries for the missing codes using their most recent descriptions\n",
    "missing_codes_df = WWEIA_ALL[WWEIA_ALL['DRXFDCD'].isin(missing_from_harmonization)]\n",
    "\n",
    "# For missing codes, get the most recent description from the original data\n",
    "missing_harmonized = (missing_codes_df\n",
    "                     .sort_values('CYCLE', ascending=False)\n",
    "                     .groupby('DRXFDCD')\n",
    "                     .agg({'DRXFCLD': 'first'})\n",
    "                     .reset_index())\n",
    "\n",
    "print(f\"Missing codes to add: {len(missing_harmonized)}\")\n",
    "\n",
    "# Combine with your existing harmonized data\n",
    "complete_harmonized_df = pd.concat([\n",
    "    harmonized_codes,\n",
    "    missing_harmonized\n",
    "], ignore_index=True)\n",
    "\n",
    "print(f\"Complete harmonized lookup: {len(complete_harmonized_df)} codes\")\n",
    "print(f\"Should equal original unique codes: {WWEIA_ALL['DRXFDCD'].nunique()}\")\n",
    "\n",
    "# Verify we have all codes now\n",
    "missing_check = set(WWEIA_ALL['DRXFDCD']) - set(complete_harmonized_df['DRXFDCD'])\n",
    "print(f\"Still missing after adding: {len(missing_check)} codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d3d84c5-5913-4dce-8242-c5c9a56b6cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final harmonized dataset:\n",
      "Shape: (2124046, 33)\n",
      "Original unique descriptions: 13327\n",
      "Final harmonized unique descriptions: 9613\n",
      "Missing descriptions: 0\n",
      "Reduced descriptions by: 3714 (27.9%)\n"
     ]
    }
   ],
   "source": [
    "# Now apply the complete harmonization to your full dataset\n",
    "WWEIA_ALL_harmonized_final = WWEIA_ALL.merge(\n",
    "    complete_harmonized_df[['DRXFDCD', 'DRXFCLD']], \n",
    "    on='DRXFDCD', \n",
    "    how='left',\n",
    "    suffixes=('_old', '_harmonized')\n",
    ")\n",
    "\n",
    "# Replace descriptions\n",
    "WWEIA_ALL_harmonized_final['DRXFCLD'] = WWEIA_ALL_harmonized_final['DRXFCLD_harmonized']\n",
    "WWEIA_ALL_harmonized_final = WWEIA_ALL_harmonized_final.drop(['DRXFCLD_old', 'DRXFCLD_harmonized'], axis=1)\n",
    "\n",
    "# Final check\n",
    "print(f\"Final harmonized dataset:\")\n",
    "print(f\"Shape: {WWEIA_ALL_harmonized_final.shape}\")\n",
    "print(f\"Original unique descriptions: {WWEIA_ALL['DRXFCLD'].nunique()}\")\n",
    "print(f\"Final harmonized unique descriptions: {WWEIA_ALL_harmonized_final['DRXFCLD'].nunique()}\")\n",
    "print(f\"Missing descriptions: {WWEIA_ALL_harmonized_final['DRXFCLD'].isna().sum()}\")\n",
    "\n",
    "# Show the reduction in unique descriptions\n",
    "reduction = WWEIA_ALL['DRXFCLD'].nunique() - WWEIA_ALL_harmonized_final['DRXFCLD'].nunique()\n",
    "reduction_pct = (reduction / WWEIA_ALL['DRXFCLD'].nunique()) * 100\n",
    "print(f\"Reduced descriptions by: {reduction} ({reduction_pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a8c9e40-d163-4ba6-acba-50f88003b43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique descriptions: 9613\n",
      "This should equal unique codes after update\n",
      "\n",
      "Final results:\n",
      "Shape: (2124046, 33)\n",
      "Unique food codes: 9613\n",
      "Unique descriptions: 9613\n",
      "Perfect 1:1 mapping: True\n"
     ]
    }
   ],
   "source": [
    "# For each description, find the most recent food code based on cycle\n",
    "most_recent_codes = (WWEIA_ALL_harmonized_final\n",
    "                    .sort_values('CYCLE', ascending=False)\n",
    "                    .groupby('DRXFCLD')\n",
    "                    .agg({\n",
    "                        'DRXFDCD': 'first',  # Most recent food code\n",
    "                        'CYCLE': 'first'     # The cycle it came from\n",
    "                    })\n",
    "                    .reset_index())\n",
    "\n",
    "print(f\"Unique descriptions: {len(most_recent_codes)}\")\n",
    "print(f\"This should equal unique codes after update\")\n",
    "\n",
    "# Create the final code-to-description mapping\n",
    "final_harmonized_lookup = most_recent_codes[['DRXFDCD', 'DRXFCLD']].rename(columns={'DRXFDCD': 'DRXFDCD_updated'})\n",
    "\n",
    "# Apply the updated food codes to your dataset\n",
    "WWEIA_ALL_final = WWEIA_ALL_harmonized_final.merge(\n",
    "    most_recent_codes[['DRXFCLD', 'DRXFDCD']].rename(columns={'DRXFDCD': 'DRXFDCD_updated'}),\n",
    "    on='DRXFCLD',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Replace the old food codes with the updated ones\n",
    "WWEIA_ALL_final['DRXFDCD'] = WWEIA_ALL_final['DRXFDCD_updated']\n",
    "WWEIA_ALL_final = WWEIA_ALL_final.drop('DRXFDCD_updated', axis=1)\n",
    "\n",
    "# Check the results\n",
    "print(f\"\\nFinal results:\")\n",
    "print(f\"Shape: {WWEIA_ALL_final.shape}\")\n",
    "print(f\"Unique food codes: {WWEIA_ALL_final['DRXFDCD'].nunique()}\")\n",
    "print(f\"Unique descriptions: {WWEIA_ALL_final['DRXFCLD'].nunique()}\")\n",
    "print(f\"Perfect 1:1 mapping: {WWEIA_ALL_final['DRXFDCD'].nunique() == WWEIA_ALL_final['DRXFCLD'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eb60311-ab54-4640-9824-9022f6b150d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most recent codes by cycle:\n",
      "CYCLE\n",
      "03_04     193\n",
      "05_06     142\n",
      "07_08     208\n",
      "09_10     669\n",
      "11_12     445\n",
      "13_14     921\n",
      "15_16    1081\n",
      "17_20    1619\n",
      "21_22    4335\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show which cycles contributed the most recent codes\n",
    "cycle_contributions = most_recent_codes['CYCLE'].value_counts().sort_index()\n",
    "print(f\"\\nMost recent codes by cycle:\")\n",
    "print(cycle_contributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7efbd16-f873-4eb8-851c-8c8acc411774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the uniques list of food codes and descriptions for generating in the food tree later on\n",
    "final_harmonized_lookup = final_harmonized_lookup.rename(columns={'DRXFDCD_updated':'FoodCode', 'DRXFCLD': 'Main.food.description'})\n",
    "final_harmonized_lookup['FoodCode'] = final_harmonized_lookup['FoodCode'].astype(int)\n",
    "final_harmonized_lookup['FoodID'] = final_harmonized_lookup['FoodCode']\n",
    "final_harmonized_lookup.to_csv('../../data/00/food_tree.txt', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930de6b6-9a8e-4dad-80fc-25b39e7f9a91",
   "metadata": {},
   "source": [
    "### Generate WWEIA dataset for total mixed meal (foodcode level) intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48e85894-d5f1-4349-ab21-beafd49f5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns\n",
    "wweia_foodcode = WWEIA_ALL_final[['SEQN', 'DRXFDCD', 'DRXFCLD', 'DR2IGRMS', 'DR2IKCAL', 'DR2IMOIS',\n",
    "       'diet_day', 'diet_wts', 'RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'RIDEXPRG',\n",
    "       'DMDBORN', 'INDFMPIR', 'DMDEDUC2', 'CYCLE']]\n",
    "\n",
    "# make to copy to modify\n",
    "wweia_foodcode = wweia_foodcode.copy()\n",
    "\n",
    "# rename columns so they are readable\n",
    "wweia_foodcode.rename(columns={'DRXFDCD': 'foodcode', 'DRXFCLD': 'food_description', 'DR2IGRMS': 'foodcode_intake_g', 'DR2IKCAL': 'foodcode_kcal'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "277d8741-ae2b-490d-ba10-09fdcd9f7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average intake over 2 diet recall days (mixed meals)\n",
    "# sum intakes\n",
    "foodcode_sum = wweia_foodcode.groupby(['SEQN', 'diet_day', 'foodcode', 'food_description'])[['foodcode_intake_g', 'foodcode_kcal']].agg(np.sum).reset_index()\n",
    "foodcode_sum.set_index(['SEQN', 'diet_day', 'foodcode', 'food_description'],inplace=True)\n",
    "r_sum = foodcode_sum.unstack(level=['diet_day'], fill_value=0).stack()\n",
    "r_sum.reset_index(inplace=True)\n",
    "\n",
    "# average intakes\n",
    "foodcode_mean = r_sum.groupby(['SEQN', 'foodcode', 'food_description'])[['foodcode_intake_g', 'foodcode_kcal']].mean().reset_index()\n",
    "\n",
    "# Save dataset\n",
    "foodcode_mean.to_csv('../../data/00/wweia_dataset/wweia_foodcode_recalls_2023.csv', index=None)\n",
    "\n",
    "# will add metadata from the ingredients dataset in the next script (01_build_wweia_2023.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e1d9dd-6424-4230-b401-5d17e59e2c10",
   "metadata": {},
   "source": [
    "### Generate the WWEIA FPED data from the foodcode level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "155b5dde-3928-4786-a961-4e8172d64666",
   "metadata": {},
   "outputs": [],
   "source": [
    "foodcode_mean['foodcode'] = foodcode_mean['foodcode'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee809042-52ea-4cab-9298-fbeb953e7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fped = pd.read_csv('../../data/00/wweia_fped/wweia_fped_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edd86b99-aa74-4582-b618-c35ed2d9254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fped = fped.rename(columns={'FOODCODE':'foodcode'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0fa97ac-ddff-41d7-b7f5-c8120f04dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fped_code = foodcode_mean.merge(fped, on='foodcode',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b6d625b-405d-4700-91cd-1ca7a59dace1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.3 percent of total items without FPED\n"
     ]
    }
   ],
   "source": [
    "fped_code[fped_code['DESCRIPTION'].isna()].drop_duplicates(subset='food_description')\n",
    "# 116 foodcode corresponding to 4652 rows missing in FPED data\n",
    "print()\n",
    "print(round(4652/(1596766-4652),3)*100, 'percent of total items without FPED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f58ae46-2ff6-44e8-9d2e-fe47dc71460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NAs (the 4652 rows missing FPED data)\n",
    "fped_code = fped_code.dropna()\n",
    "\n",
    "# drop cycle column, no longer needed\n",
    "fped_code = fped_code.drop(columns='cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc86e077-23b0-403d-b404-22399399ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fped_code.to_csv('../../data/00/wweia_dataset/wweia_fped_recalls_2023.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "284005d6-a7d5-48d1-9c8b-29ce5f42d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "foodcat = pd.read_csv('../../data/00/wweia_foodcat/wweia_foodcat_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c08a81f-5284-492a-a3b0-da49bc32706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "foodcat = foodcat.rename(columns={'food_code':'foodcode'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d94b453a-1f9f-4caa-a920-bd2b7d5f8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_cat = foodcode_mean.merge(foodcat, on='foodcode',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ef9110a-448f-43bd-9e87-4619d955b03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>foodcode</th>\n",
       "      <th>food_description</th>\n",
       "      <th>foodcode_intake_g</th>\n",
       "      <th>foodcode_kcal</th>\n",
       "      <th>food_code_description</th>\n",
       "      <th>category_number</th>\n",
       "      <th>category_description</th>\n",
       "      <th>cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>21006.0</td>\n",
       "      <td>58106530</td>\n",
       "      <td>Pizza with meat, thick crust</td>\n",
       "      <td>49.500</td>\n",
       "      <td>152.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>21007.0</td>\n",
       "      <td>58106520</td>\n",
       "      <td>Pizza with meat, thin crust</td>\n",
       "      <td>38.170</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>21015.0</td>\n",
       "      <td>92520910</td>\n",
       "      <td>Lemonade, low calorie</td>\n",
       "      <td>52.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>21024.0</td>\n",
       "      <td>57340700</td>\n",
       "      <td>Scooby Doo cereal, Kellogg's</td>\n",
       "      <td>26.460</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>21025.0</td>\n",
       "      <td>92541020</td>\n",
       "      <td>Lemonade-flavored drink, made from powdered mi...</td>\n",
       "      <td>273.440</td>\n",
       "      <td>101.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164416</th>\n",
       "      <td>29945.0</td>\n",
       "      <td>11212100</td>\n",
       "      <td>Milk, evaporated, skim, undiluted</td>\n",
       "      <td>8.000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167346</th>\n",
       "      <td>30103.0</td>\n",
       "      <td>27250510</td>\n",
       "      <td>Fish cake (Kamaboko) tempura</td>\n",
       "      <td>57.000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169243</th>\n",
       "      <td>30203.0</td>\n",
       "      <td>61222000</td>\n",
       "      <td>Pineapple-grapefruit juice, NFS</td>\n",
       "      <td>164.065</td>\n",
       "      <td>74.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170076</th>\n",
       "      <td>30251.0</td>\n",
       "      <td>92510950</td>\n",
       "      <td>Guava juice drink</td>\n",
       "      <td>313.000</td>\n",
       "      <td>171.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188323</th>\n",
       "      <td>31228.0</td>\n",
       "      <td>57347500</td>\n",
       "      <td>Strawberry Squares Mini-Wheats, Kellogg's (for...</td>\n",
       "      <td>36.095</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SEQN  foodcode                                   food_description  \\\n",
       "40      21006.0  58106530                       Pizza with meat, thick crust   \n",
       "56      21007.0  58106520                        Pizza with meat, thin crust   \n",
       "214     21015.0  92520910                              Lemonade, low calorie   \n",
       "371     21024.0  57340700                       Scooby Doo cereal, Kellogg's   \n",
       "400     21025.0  92541020  Lemonade-flavored drink, made from powdered mi...   \n",
       "...         ...       ...                                                ...   \n",
       "164416  29945.0  11212100                  Milk, evaporated, skim, undiluted   \n",
       "167346  30103.0  27250510                       Fish cake (Kamaboko) tempura   \n",
       "169243  30203.0  61222000                    Pineapple-grapefruit juice, NFS   \n",
       "170076  30251.0  92510950                                  Guava juice drink   \n",
       "188323  31228.0  57347500  Strawberry Squares Mini-Wheats, Kellogg's (for...   \n",
       "\n",
       "        foodcode_intake_g  foodcode_kcal food_code_description  \\\n",
       "40                 49.500          152.5                   NaN   \n",
       "56                 38.170          112.0                   NaN   \n",
       "214                52.500            1.0                   NaN   \n",
       "371                26.460          115.0                   NaN   \n",
       "400               273.440          101.5                   NaN   \n",
       "...                   ...            ...                   ...   \n",
       "164416              8.000            6.0                   NaN   \n",
       "167346             57.000           94.0                   NaN   \n",
       "169243            164.065           74.5                   NaN   \n",
       "170076            313.000          171.5                   NaN   \n",
       "188323             36.095          121.0                   NaN   \n",
       "\n",
       "        category_number category_description  cycle  \n",
       "40                  NaN                  NaN    NaN  \n",
       "56                  NaN                  NaN    NaN  \n",
       "214                 NaN                  NaN    NaN  \n",
       "371                 NaN                  NaN    NaN  \n",
       "400                 NaN                  NaN    NaN  \n",
       "...                 ...                  ...    ...  \n",
       "164416              NaN                  NaN    NaN  \n",
       "167346              NaN                  NaN    NaN  \n",
       "169243              NaN                  NaN    NaN  \n",
       "170076              NaN                  NaN    NaN  \n",
       "188323              NaN                  NaN    NaN  \n",
       "\n",
       "[87 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 87 unique foodcodes without a WWEIA food category and 4203 total rows missing\n",
    "code_cat[code_cat['category_description'].isna()].drop_duplicates(subset='food_description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cf1bb3f-5a60-4db4-8f30-b6deb3a74a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 percent of total items without a food category\n"
     ]
    }
   ],
   "source": [
    "print(round(4203/(1596766+4203),3)*100, 'percent of total items without a food category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d95f9456-5c12-4aab-92a7-34ef2b4d7391",
   "metadata": {},
   "outputs": [],
   "source": [
    "foodcat_all = code_cat.groupby(['SEQN', 'category_number', 'category_description'])[['foodcode_intake_g', 'foodcode_kcal']].agg(np.sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e26b4acc-316d-4712-af2a-96502840509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "foodcat_all.to_csv('../../data/00/wweia_dataset/wweia_foodcat_recalls_2023.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ecf4aa-75e7-4c9f-9570-2cf9e99d74d1",
   "metadata": {},
   "source": [
    "### Generate WWEIA total nutrients dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1ac41f1-96cd-4027-bfb5-38459856f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Total Nutritent Intake Data for Day 1 and 2:\n",
    "import pandas as pd\n",
    "\n",
    "nut_1_C = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2003/DataFiles/DR1TOT_C.xpt', format='xport', encoding='utf-8')\n",
    "nut_2_C = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2003/DataFiles/DR2TOT_C.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "nut_1_D = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2005/DataFiles/DR1TOT_D.xpt', format='xport', encoding='utf-8')\n",
    "nut_2_D = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2005/DataFiles/DR2TOT_D.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "nut_1_E = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2007/DataFiles/DR1TOT_E.xpt', format='xport', encoding='utf-8')\n",
    "nut_2_E = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2007/DataFiles/DR2TOT_E.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "nut_1_F = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2009/DataFiles/DR1TOT_F.xpt', format='xport', encoding='utf-8')\n",
    "nut_2_F = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2009/DataFiles/DR2TOT_F.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "nut_1_G = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2011/DataFiles/DR1TOT_G.xpt', format='xport', encoding='utf-8')\n",
    "nut_2_G = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2011/DataFiles/DR2TOT_G.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "nut_1_H = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2013/DataFiles/DR1TOT_H.xpt', format='xport', encoding='utf-8')\n",
    "nut_2_H = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2013/DataFiles/DR2TOT_H.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "nut_1_I = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2015/DataFiles/DR1TOT_I.xpt', format='xport', encoding='utf-8')\n",
    "nut_2_I = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2015/DataFiles/DR2TOT_I.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "nut_1_P = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/P_DR1TOT.xpt', format='xport', encoding='utf-8')\n",
    "nut_2_P = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/P_DR2TOT.xpt', format='xport', encoding='utf-8')\n",
    "\n",
    "nut_1_L = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/DR1TOT_L.xpt', format='xport', encoding='utf-8')\n",
    "nut_2_L = pd.read_sas('https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/DR2TOT_L.xpt', format='xport', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c060ebb7-a53a-49e5-ad5c-b9df33177b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean datasets by keeping only particpants with 2 recall days 'DRDINT' == 2 and passing quality control 'DR1DRSTZ' == 1\n",
    "# each cycle has two days of nutrient intakes (corresponding to the 24-hr recall), e.g., nut_1_C and nut_2_C\n",
    "\n",
    "nut_1_C = nut_1_C[nut_1_C['DRDINT']==2]\n",
    "nut_1_C = nut_1_C[nut_1_C['DR1DRSTZ']==1]\n",
    "\n",
    "nut_2_C = nut_2_C[nut_2_C['DRDINT']==2]\n",
    "nut_2_C = nut_2_C[nut_2_C['DR2DRSTZ']==1]\n",
    "\n",
    "nut_1_D = nut_1_D[nut_1_D['DRDINT']==2]\n",
    "nut_1_D = nut_1_D[nut_1_D['DR1DRSTZ']==1]\n",
    "\n",
    "nut_2_D = nut_2_D[nut_2_D['DRDINT']==2]\n",
    "nut_2_D = nut_2_D[nut_2_D['DR2DRSTZ']==1]\n",
    "\n",
    "nut_1_F = nut_1_F[nut_1_F['DRDINT']==2]\n",
    "nut_1_F = nut_1_F[nut_1_F['DR1DRSTZ']==1]\n",
    "\n",
    "nut_2_F = nut_2_F[nut_2_F['DRDINT']==2]\n",
    "nut_2_F = nut_2_F[nut_2_F['DR2DRSTZ']==1]\n",
    "\n",
    "nut_1_G = nut_1_G[nut_1_G['DRDINT']==2]\n",
    "nut_1_G = nut_1_G[nut_1_G['DR1DRSTZ']==1]\n",
    "\n",
    "nut_2_G = nut_2_G[nut_2_G['DRDINT']==2]\n",
    "nut_2_G = nut_2_G[nut_2_G['DR2DRSTZ']==1]\n",
    "\n",
    "nut_1_H = nut_1_H[nut_1_H['DRDINT']==2]\n",
    "nut_1_H = nut_1_H[nut_1_H['DR1DRSTZ']==1]\n",
    "\n",
    "nut_2_H = nut_2_H[nut_2_H['DRDINT']==2]\n",
    "nut_2_H = nut_2_H[nut_2_H['DR2DRSTZ']==1]\n",
    "\n",
    "nut_1_I = nut_1_I[nut_1_I['DRDINT']==2]\n",
    "nut_1_I = nut_1_I[nut_1_I['DR1DRSTZ']==1]\n",
    "\n",
    "nut_2_I = nut_2_I[nut_2_I['DRDINT']==2]\n",
    "nut_2_I = nut_2_I[nut_2_I['DR2DRSTZ']==1]\n",
    "\n",
    "nut_1_P = nut_1_P[nut_1_P['DRDINT']==2]\n",
    "nut_1_P = nut_1_P[nut_1_P['DR1DRSTZ']==1]\n",
    "\n",
    "nut_2_P = nut_2_P[nut_2_P['DRDINT']==2]\n",
    "nut_2_P = nut_2_P[nut_2_P['DR2DRSTZ']==1]\n",
    "\n",
    "nut_1_L = nut_1_L[nut_1_L['DRDINT']==2]\n",
    "nut_1_L = nut_1_L[nut_1_L['DR1DRSTZ']==1]\n",
    "\n",
    "nut_2_L = nut_2_L[nut_2_L['DRDINT']==2]\n",
    "nut_2_L = nut_2_L[nut_2_L['DR2DRSTZ']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b4f5ab2-80e8-4042-bef7-a830c08b9596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing each cycle pair:\n",
      "--------------------------------------------------\n",
      "Cycle C:\n",
      "  Common SEQN values: 8213\n",
      "  nut_1_C: (8214, 160)  (8213, 160)\n",
      "  nut_2_C: (8220, 81)  (8213, 81)\n",
      "\n",
      "Cycle D:\n",
      "  Common SEQN values: 8257\n",
      "  nut_1_D: (8261, 160)  (8257, 160)\n",
      "  nut_2_D: (8264, 81)  (8257, 81)\n",
      "\n",
      "Cycle E:\n",
      "  Common SEQN values: 9762\n",
      "  nut_1_E: (9762, 164)  (9762, 164)\n",
      "  nut_2_E: (9762, 83)  (9762, 83)\n",
      "\n",
      "Cycle F:\n",
      "  Common SEQN values: 8279\n",
      "  nut_1_F: (8284, 166)  (8279, 166)\n",
      "  nut_2_F: (8288, 83)  (8279, 83)\n",
      "\n",
      "Cycle G:\n",
      "  Common SEQN values: 7486\n",
      "  nut_1_G: (7486, 166)  (7486, 166)\n",
      "  nut_2_G: (7496, 83)  (7486, 83)\n",
      "\n",
      "Cycle H:\n",
      "  Common SEQN values: 7449\n",
      "  nut_1_H: (7453, 168)  (7449, 168)\n",
      "  nut_2_H: (7453, 85)  (7449, 85)\n",
      "\n",
      "Cycle I:\n",
      "  Common SEQN values: 6863\n",
      "  nut_1_I: (6864, 168)  (6863, 168)\n",
      "  nut_2_I: (6875, 85)  (6863, 85)\n",
      "\n",
      "Cycle P:\n",
      "  Common SEQN values: 10610\n",
      "  nut_1_P: (10612, 168)  (10610, 168)\n",
      "  nut_2_P: (10627, 85)  (10610, 85)\n",
      "\n",
      "Cycle L:\n",
      "  Common SEQN values: 5828\n",
      "  nut_1_L: (5828, 168)  (5828, 168)\n",
      "  nut_2_L: (5830, 85)  (5828, 85)\n",
      "\n",
      "All cycle pairs processed!\n",
      "\n",
      "Filtered datasets are available as:\n",
      "  nut_1_C_filtered and nut_2_C_filtered\n",
      "  nut_1_D_filtered and nut_2_D_filtered\n",
      "  nut_1_E_filtered and nut_2_E_filtered\n",
      "  nut_1_F_filtered and nut_2_F_filtered\n",
      "  nut_1_G_filtered and nut_2_G_filtered\n",
      "  nut_1_H_filtered and nut_2_H_filtered\n",
      "  nut_1_I_filtered and nut_2_I_filtered\n",
      "  nut_1_P_filtered and nut_2_P_filtered\n",
      "  nut_1_L_filtered and nut_2_L_filtered\n"
     ]
    }
   ],
   "source": [
    "# For each cycle get SEQN IDs common for day 1 and day 2 recalls\n",
    "\n",
    "# Define the cycles for your datasets\n",
    "cycle = ['C', 'D', 'E', 'F', 'G', 'H', 'I', 'P', 'L']\n",
    "\n",
    "# Store your datasets in dictionaries for easy access\n",
    "nut_1_datasets = {}\n",
    "nut_2_datasets = {}\n",
    "\n",
    "# Load your datasets (replace with your actual loading method)\n",
    "for letter in cycle:\n",
    "    \n",
    "    # For now, assuming they're already in memory:\n",
    "    nut_1_datasets[letter] = globals()[f'nut_1_{letter}']\n",
    "    nut_2_datasets[letter] = globals()[f'nut_2_{letter}']\n",
    "\n",
    "# Filter each pair of datasets to include only matching SEQN values\n",
    "nut_1_filtered = {}\n",
    "nut_2_filtered = {}\n",
    "\n",
    "print(\"Processing each cycle pair:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for letter in cycle:\n",
    "    # Find common SEQN values between the pair\n",
    "    common_seqn_pair = set(nut_1_datasets[letter]['SEQN']).intersection(\n",
    "        set(nut_2_datasets[letter]['SEQN'])\n",
    "    )\n",
    "    \n",
    "    # Filter each dataset in the pair\n",
    "    nut_1_filtered[letter] = nut_1_datasets[letter][\n",
    "        nut_1_datasets[letter]['SEQN'].isin(common_seqn_pair)\n",
    "    ]\n",
    "    nut_2_filtered[letter] = nut_2_datasets[letter][\n",
    "        nut_2_datasets[letter]['SEQN'].isin(common_seqn_pair)\n",
    "    ]\n",
    "    \n",
    "    # Print summary for this pair\n",
    "    print(f\"Cycle {letter}:\")\n",
    "    print(f\"  Common SEQN values: {len(common_seqn_pair)}\")\n",
    "    print(f\"  nut_1_{letter}: {nut_1_datasets[letter].shape}  {nut_1_filtered[letter].shape}\")\n",
    "    print(f\"  nut_2_{letter}: {nut_2_datasets[letter].shape}  {nut_2_filtered[letter].shape}\")\n",
    "    print()\n",
    "\n",
    "print(\"All cycle pairs processed!\")\n",
    "print(\"\\nFiltered datasets are available as:\")\n",
    "for letter in cycle:\n",
    "    print(f\"  nut_1_{letter}_filtered and nut_2_{letter}_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2aeeb83-ab37-4ec2-b774-c165a88ef854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonize the names of the features in the nutrients data cycles\n",
    "\n",
    "# Day 1 rename dictionary:\n",
    "rename_dict_day1 = {\n",
    "    'DR1TKCAL': 'Energy (kcal)',\n",
    "    'DR1TPROT': 'Protein (gm)',\n",
    "    'DR1TCARB': 'Carbohydrate (gm)',\n",
    "    'DR1TSUGR': 'Total sugars (gm)',\n",
    "    'DR1TFIBE': 'Dietary fiber (gm)',\n",
    "    'DR1TTFAT': 'Total fat (gm)',\n",
    "    'DR1TSFAT': 'Total saturated fatty acids (gm)',\n",
    "    'DR1TMFAT': 'Total monounsaturated fatty acids (gm)',\n",
    "    'DR1TPFAT': 'Total polyunsaturated fatty acids (gm)',\n",
    "    'DR1TCHOL': 'Cholesterol (mg)',\n",
    "    'DR1TATOC': 'Vitamin E as alpha-tocopherol (mg)',\n",
    "    'DR1TATOA': 'Added alpha-tocopherol (Vitamin E) (mg)',\n",
    "    'DR1TRET': 'Retinol (mcg)',\n",
    "    'DR1TVARA': 'Vitamin A, RAE (mcg)',\n",
    "    'DR1TACAR': 'Alpha-carotene (mcg)',\n",
    "    'DR1TBCAR': 'Beta-carotene (mcg)',\n",
    "    'DR1TCRYP': 'Beta-cryptoxanthin (mcg)',\n",
    "    'DR1TLYCO': 'Lycopene (mcg)',\n",
    "    'DR1TLZ': 'Lutein + zeaxanthin (mcg)',\n",
    "    'DR1TVB1': 'Thiamin (Vitamin B1) (mg)',\n",
    "    'DR1TVB2': 'Riboflavin (Vitamin B2) (mg)',\n",
    "    'DR1TNIAC': 'Niacin (mg)',\n",
    "    'DR1TVB6': 'Vitamin B6 (mg)',\n",
    "    'DR1TFOLA': 'Total Folate (mcg)',\n",
    "    'DR1TFA': 'Folic acid (mcg)',\n",
    "    'DR1TFF': 'Food folate (mcg)',\n",
    "    'DR1TFDFE': 'Folate, DFE (mcg)',\n",
    "    'DR1TVB12': 'Vitamin B12 (mcg)',\n",
    "    'DR1TB12A': 'Added vitamin B12 (mcg)',\n",
    "    'DR1TVC': 'Vitamin C (mg)',\n",
    "    'DR1TVK': 'Vitamin K (mcg)',\n",
    "    'DR1TCALC': 'Calcium (mg)',\n",
    "    'DR1TPHOS': 'Phosphorus (mg)',\n",
    "    'DR1TMAGN': 'Magnesium (mg)',\n",
    "    'DR1TIRON': 'Iron (mg)',\n",
    "    'DR1TZINC': 'Zinc (mg)',\n",
    "    'DR1TCOPP': 'Copper (mg)',\n",
    "    'DR1TSODI': 'Sodium (mg)',\n",
    "    'DR1TPOTA': 'Potassium (mg)',\n",
    "    'DR1TSELE': 'Selenium (mcg)',\n",
    "    'DR1TCAFF': 'Caffeine (mg)',\n",
    "    'DR1TTHEO': 'Theobromine (mg)',\n",
    "    'DR1TALCO': 'Alcohol (gm)',\n",
    "    'DR1TMOIS': 'Moisture (gm)',\n",
    "    'DR1TS040': 'SFA 4:0 (Butanoic) (gm)',\n",
    "    'DR1TS060': 'SFA 6:0 (Hexanoic) (gm)',\n",
    "    'DR1TS080': 'SFA 8:0 (Octanoic) (gm)',\n",
    "    'DR1TS100': 'SFA 10:0 (Decanoic) (gm)',\n",
    "    'DR1TS120': 'SFA 12:0 (Dodecanoic) (gm)',\n",
    "    'DR1TS140': 'SFA 14:0 (Tetradecanoic) (gm)',\n",
    "    'DR1TS160': 'SFA 16:0 (Hexadecanoic) (gm)',\n",
    "    'DR1TS180': 'SFA 18:0 (Octadecanoic) (gm)',\n",
    "    'DR1TM161': 'MFA 16:1 (Hexadecenoic) (gm)',\n",
    "    'DR1TM181': 'MFA 18:1 (Octadecenoic) (gm)',\n",
    "    'DR1TM201': 'MFA 20:1 (Eicosenoic) (gm)',\n",
    "    'DR1TM221': 'MFA 22:1 (Docosenoic) (gm)',\n",
    "    'DR1TP182': 'PFA 18:2 (Octadecadienoic) (gm)',\n",
    "    'DR1TP183': 'PFA 18:3 (Octadecatrienoic) (gm)',\n",
    "    'DR1TP184': 'PFA 18:4 (Octadecatetraenoic) (gm)',\n",
    "    'DR1TP204': 'PFA 20:4 (Eicosatetraenoic) (gm)',\n",
    "    'DR1TP205': 'PFA 20:5 (Eicosapentaenoic) (gm)',\n",
    "    'DR1TP225': 'PFA 22:5 (Docosapentaenoic) (gm)',\n",
    "    'DR1TP226': 'PFA 22:6 (Docosahexaenoic) (gm)'\n",
    "}\n",
    "\n",
    "# Day 2 rename dictionary\n",
    "rename_dict_day2 = {\n",
    "    'DR2TKCAL': 'Energy (kcal)',\n",
    "    'DR2TPROT': 'Protein (gm)',\n",
    "    'DR2TCARB': 'Carbohydrate (gm)',\n",
    "    'DR2TSUGR': 'Total sugars (gm)',\n",
    "    'DR2TFIBE': 'Dietary fiber (gm)',\n",
    "    'DR2TTFAT': 'Total fat (gm)',\n",
    "    'DR2TSFAT': 'Total saturated fatty acids (gm)',\n",
    "    'DR2TMFAT': 'Total monounsaturated fatty acids (gm)',\n",
    "    'DR2TPFAT': 'Total polyunsaturated fatty acids (gm)',\n",
    "    'DR2TCHOL': 'Cholesterol (mg)',\n",
    "    'DR2TATOC': 'Vitamin E as alpha-tocopherol (mg)',\n",
    "    'DR2TATOA': 'Added alpha-tocopherol (Vitamin E) (mg)',\n",
    "    'DR2TRET': 'Retinol (mcg)',\n",
    "    'DR2TVARA': 'Vitamin A, RAE (mcg)',\n",
    "    'DR2TACAR': 'Alpha-carotene (mcg)',\n",
    "    'DR2TBCAR': 'Beta-carotene (mcg)',\n",
    "    'DR2TCRYP': 'Beta-cryptoxanthin (mcg)',\n",
    "    'DR2TLYCO': 'Lycopene (mcg)',\n",
    "    'DR2TLZ': 'Lutein + zeaxanthin (mcg)',\n",
    "    'DR2TVB1': 'Thiamin (Vitamin B1) (mg)',\n",
    "    'DR2TVB2': 'Riboflavin (Vitamin B2) (mg)',\n",
    "    'DR2TNIAC': 'Niacin (mg)',\n",
    "    'DR2TVB6': 'Vitamin B6 (mg)',\n",
    "    'DR2TFOLA': 'Total Folate (mcg)',\n",
    "    'DR2TFA': 'Folic acid (mcg)',\n",
    "    'DR2TFF': 'Food folate (mcg)',\n",
    "    'DR2TFDFE': 'Folate, DFE (mcg)',\n",
    "    'DR2TVB12': 'Vitamin B12 (mcg)',\n",
    "    'DR2TB12A': 'Added vitamin B12 (mcg)',\n",
    "    'DR2TVC': 'Vitamin C (mg)',\n",
    "    'DR2TVK': 'Vitamin K (mcg)',\n",
    "    'DR2TCALC': 'Calcium (mg)',\n",
    "    'DR2TPHOS': 'Phosphorus (mg)',\n",
    "    'DR2TMAGN': 'Magnesium (mg)',\n",
    "    'DR2TIRON': 'Iron (mg)',\n",
    "    'DR2TZINC': 'Zinc (mg)',\n",
    "    'DR2TCOPP': 'Copper (mg)',\n",
    "    'DR2TSODI': 'Sodium (mg)',\n",
    "    'DR2TPOTA': 'Potassium (mg)',\n",
    "    'DR2TSELE': 'Selenium (mcg)',\n",
    "    'DR2TCAFF': 'Caffeine (mg)',\n",
    "    'DR2TTHEO': 'Theobromine (mg)',\n",
    "    'DR2TALCO': 'Alcohol (gm)',\n",
    "    'DR2TMOIS': 'Moisture (gm)',\n",
    "    'DR2TS040': 'SFA 4:0 (Butanoic) (gm)',\n",
    "    'DR2TS060': 'SFA 6:0 (Hexanoic) (gm)',\n",
    "    'DR2TS080': 'SFA 8:0 (Octanoic) (gm)',\n",
    "    'DR2TS100': 'SFA 10:0 (Decanoic) (gm)',\n",
    "    'DR2TS120': 'SFA 12:0 (Dodecanoic) (gm)',\n",
    "    'DR2TS140': 'SFA 14:0 (Tetradecanoic) (gm)',\n",
    "    'DR2TS160': 'SFA 16:0 (Hexadecanoic) (gm)',\n",
    "    'DR2TS180': 'SFA 18:0 (Octadecanoic) (gm)',\n",
    "    'DR2TM161': 'MFA 16:1 (Hexadecenoic) (gm)',\n",
    "    'DR2TM181': 'MFA 18:1 (Octadecenoic) (gm)',\n",
    "    'DR2TM201': 'MFA 20:1 (Eicosenoic) (gm)',\n",
    "    'DR2TM221': 'MFA 22:1 (Docosenoic) (gm)',\n",
    "    'DR2TP182': 'PFA 18:2 (Octadecadienoic) (gm)',\n",
    "    'DR2TP183': 'PFA 18:3 (Octadecatrienoic) (gm)',\n",
    "    'DR2TP184': 'PFA 18:4 (Octadecatetraenoic) (gm)',\n",
    "    'DR2TP204': 'PFA 20:4 (Eicosatetraenoic) (gm)',\n",
    "    'DR2TP205': 'PFA 20:5 (Eicosapentaenoic) (gm)',\n",
    "    'DR2TP225': 'PFA 22:5 (Docosapentaenoic) (gm)',\n",
    "    'DR2TP226': 'PFA 22:6 (Docosahexaenoic) (gm)'\n",
    "}\n",
    "\n",
    "# New column names for selection\n",
    "new_column_names = [\n",
    "    'SEQN',\n",
    "    'Energy (kcal)',\n",
    "    'Protein (gm)',\n",
    "    'Carbohydrate (gm)',\n",
    "    'Total sugars (gm)',\n",
    "    'Dietary fiber (gm)',\n",
    "    'Total fat (gm)',\n",
    "    'Total saturated fatty acids (gm)',\n",
    "    'Total monounsaturated fatty acids (gm)',\n",
    "    'Total polyunsaturated fatty acids (gm)',\n",
    "    'Cholesterol (mg)',\n",
    "    'Vitamin E as alpha-tocopherol (mg)',\n",
    "    'Added alpha-tocopherol (Vitamin E) (mg)',\n",
    "    'Retinol (mcg)',\n",
    "    'Vitamin A, RAE (mcg)',\n",
    "    'Alpha-carotene (mcg)',\n",
    "    'Beta-carotene (mcg)',\n",
    "    'Beta-cryptoxanthin (mcg)',\n",
    "    'Lycopene (mcg)',\n",
    "    'Lutein + zeaxanthin (mcg)',\n",
    "    'Thiamin (Vitamin B1) (mg)',\n",
    "    'Riboflavin (Vitamin B2) (mg)',\n",
    "    'Niacin (mg)',\n",
    "    'Vitamin B6 (mg)',\n",
    "    'Total Folate (mcg)',\n",
    "    'Folic acid (mcg)',\n",
    "    'Food folate (mcg)',\n",
    "    'Folate, DFE (mcg)',\n",
    "    'Vitamin B12 (mcg)',\n",
    "    'Added vitamin B12 (mcg)',\n",
    "    'Vitamin C (mg)',\n",
    "    'Vitamin K (mcg)',\n",
    "    'Calcium (mg)',\n",
    "    'Phosphorus (mg)',\n",
    "    'Magnesium (mg)',\n",
    "    'Iron (mg)',\n",
    "    'Zinc (mg)',\n",
    "    'Copper (mg)',\n",
    "    'Sodium (mg)',\n",
    "    'Potassium (mg)',\n",
    "    'Selenium (mcg)',\n",
    "    'Caffeine (mg)',\n",
    "    'Theobromine (mg)',\n",
    "    'Alcohol (gm)',\n",
    "    'Moisture (gm)',\n",
    "    'SFA 4:0 (Butanoic) (gm)',\n",
    "    'SFA 6:0 (Hexanoic) (gm)',\n",
    "    'SFA 8:0 (Octanoic) (gm)',\n",
    "    'SFA 10:0 (Decanoic) (gm)',\n",
    "    'SFA 12:0 (Dodecanoic) (gm)',\n",
    "    'SFA 14:0 (Tetradecanoic) (gm)',\n",
    "    'SFA 16:0 (Hexadecanoic) (gm)',\n",
    "    'SFA 18:0 (Octadecanoic) (gm)',\n",
    "    'MFA 16:1 (Hexadecenoic) (gm)',\n",
    "    'MFA 18:1 (Octadecenoic) (gm)',\n",
    "    'MFA 20:1 (Eicosenoic) (gm)',\n",
    "    'MFA 22:1 (Docosenoic) (gm)',\n",
    "    'PFA 18:2 (Octadecadienoic) (gm)',\n",
    "    'PFA 18:3 (Octadecatrienoic) (gm)',\n",
    "    'PFA 18:4 (Octadecatetraenoic) (gm)',\n",
    "    'PFA 20:4 (Eicosatetraenoic) (gm)',\n",
    "    'PFA 20:5 (Eicosapentaenoic) (gm)',\n",
    "    'PFA 22:5 (Docosapentaenoic) (gm)',\n",
    "    'PFA 22:6 (Docosahexaenoic) (gm)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "119c983d-ea5d-4aa2-b2ab-6d4d2f67cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns and select the nutrients in common across all cyles:\n",
    "nut_1_C_ = nut_1_filtered['C'].rename(columns=rename_dict_day1)\n",
    "nut_1_C_selected = nut_1_C_[new_column_names]\n",
    "\n",
    "nut_2_C_ = nut_2_filtered['C'].rename(columns=rename_dict_day2)\n",
    "nut_2_C_selected = nut_2_C_[new_column_names]\n",
    "\n",
    "nut_1_D_ = nut_1_filtered['D'].rename(columns=rename_dict_day1)\n",
    "nut_1_D_selected = nut_1_D_[new_column_names]\n",
    "\n",
    "nut_2_D_ = nut_2_filtered['D'].rename(columns=rename_dict_day2)\n",
    "nut_2_D_selected = nut_2_D_[new_column_names]\n",
    "\n",
    "nut_1_E_ = nut_1_filtered['E'].rename(columns=rename_dict_day1)\n",
    "nut_1_E_selected = nut_1_E_[new_column_names]\n",
    "\n",
    "nut_2_E_ = nut_2_filtered['E'].rename(columns=rename_dict_day2)\n",
    "nut_2_E_selected = nut_2_E_[new_column_names]\n",
    "\n",
    "nut_1_F_ = nut_1_filtered['F'].rename(columns=rename_dict_day1)\n",
    "nut_1_F_selected = nut_1_F_[new_column_names]\n",
    "\n",
    "nut_2_F_ = nut_2_filtered['F'].rename(columns=rename_dict_day2)\n",
    "nut_2_F_selected = nut_2_F_[new_column_names]\n",
    "\n",
    "nut_1_G_ = nut_1_filtered['G'].rename(columns=rename_dict_day1)\n",
    "nut_1_G_selected = nut_1_G_[new_column_names]\n",
    "\n",
    "nut_2_G_ = nut_2_filtered['G'].rename(columns=rename_dict_day2)\n",
    "nut_2_G_selected = nut_2_G_[new_column_names]\n",
    "\n",
    "nut_1_H_ = nut_1_filtered['H'].rename(columns=rename_dict_day1)\n",
    "nut_1_H_selected = nut_1_H_[new_column_names]\n",
    "\n",
    "nut_2_H_ = nut_2_filtered['H'].rename(columns=rename_dict_day2)\n",
    "nut_2_H_selected = nut_2_H_[new_column_names]\n",
    "\n",
    "nut_1_I_ = nut_1_filtered['I'].rename(columns=rename_dict_day1)\n",
    "nut_1_I_selected = nut_1_I_[new_column_names]\n",
    "\n",
    "nut_2_I_ = nut_2_filtered['I'].rename(columns=rename_dict_day2)\n",
    "nut_2_I_selected = nut_2_I_[new_column_names]\n",
    "\n",
    "nut_1_P_ = nut_1_filtered['P'].rename(columns=rename_dict_day1)\n",
    "nut_1_P_selected = nut_1_P_[new_column_names]\n",
    "\n",
    "nut_2_P_ = nut_2_filtered['P'].rename(columns=rename_dict_day2)\n",
    "nut_2_P_selected = nut_2_P_[new_column_names]\n",
    "\n",
    "nut_1_L_ = nut_1_filtered['L'].rename(columns=rename_dict_day1)\n",
    "nut_1_L_selected = nut_1_L_[new_column_names]\n",
    "\n",
    "nut_2_L_ = nut_2_filtered['L'].rename(columns=rename_dict_day2)\n",
    "nut_2_L_selected = nut_2_L_[new_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1e4ec69-54b9-4d3c-b5f8-bd61b85d03f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two diet recall days for each cycle\n",
    "total_nut_C = pd.concat([nut_1_C_selected, nut_2_C_selected])\n",
    "total_nut_D = pd.concat([nut_1_D_selected, nut_2_D_selected])\n",
    "total_nut_E = pd.concat([nut_1_E_selected, nut_2_E_selected])\n",
    "total_nut_F = pd.concat([nut_1_F_selected, nut_2_F_selected])\n",
    "total_nut_G = pd.concat([nut_1_G_selected, nut_2_G_selected])\n",
    "total_nut_H = pd.concat([nut_1_H_selected, nut_2_H_selected])\n",
    "total_nut_I = pd.concat([nut_1_I_selected, nut_2_I_selected])\n",
    "total_nut_P = pd.concat([nut_1_P_selected, nut_2_P_selected])\n",
    "total_nut_L = pd.concat([nut_1_L_selected, nut_2_L_selected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc12c9be-c5e8-4e61-884c-5f38c248ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and combine all cycles\n",
    "total_nut_all = pd.concat([total_nut_C, total_nut_D, total_nut_E, total_nut_F, total_nut_G, total_nut_H, total_nut_I, total_nut_P, total_nut_L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e71c9af0-6a53-4ebb-805a-c77ac6b7ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average intakes for each particpant across their two 24-hr recalls\n",
    "total_nut_mean = total_nut_all.groupby('SEQN').mean().reset_index()\n",
    "\n",
    "# save the dataset\n",
    "total_nut_mean.to_csv('../../data/00/wweia_dataset/wweia_total_nutrients_recalls_2023.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917bfaa9-fa97-4a6a-a303-3676bcf6e871",
   "metadata": {},
   "source": [
    "### Generate WWEIA ingredients dataset\n",
    "### Merge WWEIA recalls with FDA disaggreagtion database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f35de22-9d53-4672-89ef-98cc64565869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the FDA-FDD dataset (v3.0)\n",
    "fdafdd =  pd.read_csv('../../data/00/ingredient_matching/FDA_FDD_All_Records_v_3.0.csv', usecols=['WWEIA Food Code', 'WWEIA Food Description', 'Basic Ingredient Description', 'Ingredient Percent'])\n",
    "\n",
    "# rename columns for merging\n",
    "fdafdd.rename(columns={'WWEIA Food Code': 'DRXFDCD'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3da606b7-27c1-4adc-933e-60d6e77d401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of food codes that match to FDA-FDD\n",
    "unique_codes = WWEIA_ALL_final[['DRXFDCD', 'DRXFCLD']].drop_duplicates(subset='DRXFDCD')\n",
    "\n",
    "# chage to integer for merging\n",
    "unique_codes['DRXFDCD'] = unique_codes['DRXFDCD'].astype(int)\n",
    "\n",
    "# merge the WWEIA food codes with those in the FDA database\n",
    "unique_merged = unique_codes.merge(fdafdd, on='DRXFDCD', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "219bf9c2-5211-4d3c-a865-e6c165e9b0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71596, 5)\n",
      "(71595, 5)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the dataset and see how many food codes were not matched (NAs)\n",
    "\n",
    "print(unique_merged.shape)\n",
    "print(unique_merged.dropna().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7dd68f7a-a03f-419f-9606-38f62ff87838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39701    11836100\n",
      "Name: DRXFDCD, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# what was the missing foodcode?\n",
    "print(unique_merged[unique_merged.isna().any(axis=1)]['DRXFDCD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdde9bf1-6f9f-42f1-9f12-ad7f20f98d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DRXFDCD                                            DRXFCLD  \\\n",
      "39701  11836100  Protein supplement, milk-based, Muscle Milk Li...   \n",
      "\n",
      "      WWEIA Food Description Basic Ingredient Description  Ingredient Percent  \n",
      "39701                    NaN                          NaN                 NaN  \n"
     ]
    }
   ],
   "source": [
    "# one missing foodcode (protein supplement)\n",
    "missing_rows = unique_merged[unique_merged['DRXFDCD']==11836100]\n",
    "print(missing_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08f03b18-63fd-4236-adb3-36e22fcb780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate WWEIA dataset for ingredient level intake using FDA-FDD\n",
    "# first, merge the WWEIA dataset from above (food codes) with the FDA-FDD\n",
    "wweia_fda = WWEIA_ALL_final.drop(columns='DRXFCLD').merge(fdafdd, on='DRXFDCD', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d205d27-d3c0-48bc-9612-897a663f644f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 rows with NAs in the specified columns\n",
      "            DRXFDCD WWEIA Food Description Basic Ingredient Description  \\\n",
      "3086571  11836100.0                    NaN                          NaN   \n",
      "3086572  11836100.0                    NaN                          NaN   \n",
      "3086759  11836100.0                    NaN                          NaN   \n",
      "3972678  11836100.0                    NaN                          NaN   \n",
      "4219184  11836100.0                    NaN                          NaN   \n",
      "\n",
      "         Ingredient Percent  \n",
      "3086571                 NaN  \n",
      "3086572                 NaN  \n",
      "3086759                 NaN  \n",
      "3972678                 NaN  \n",
      "4219184                 NaN  \n",
      "5 missing rows is accepable\n"
     ]
    }
   ],
   "source": [
    "# Find rows where any of the specified columns has NA\n",
    "columns_of_interest = ['DRXFDCD', 'WWEIA Food Description', 'Basic Ingredient Description', 'Ingredient Percent']\n",
    "rows_with_na = wweia_fda[wweia_fda[columns_of_interest].isna().any(axis=1)]\n",
    "\n",
    "# Display only these rows, focusing on the columns of interest\n",
    "print(f\"Found {len(rows_with_na)} rows with NAs in the specified columns\")\n",
    "print(rows_with_na[columns_of_interest])\n",
    "print('5 missing rows is accepable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f050efa-2332-4af5-8c62-2bcb1174c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping NAs will remove the single foodcode 11836100 (Protein supplement)\n",
    "wweia_fda = wweia_fda.dropna(subset=['DRXFDCD', 'WWEIA Food Description', 'Basic Ingredient Description', 'Ingredient Percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa42ca28-d517-453d-bbab-d6b316c4dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save unique fda ingredient list to match with FNDDS unique ingredient list\n",
    "unique_ingred = wweia_fda[['Basic Ingredient Description']] #\n",
    "unique_ingred = unique_ingred['Basic Ingredient Description'].drop_duplicates()\n",
    "unique_ingred.to_csv('../../data/00/ingredient_matching/wweia_fda_unique_ingredients.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27b120d4-ab24-46a4-8c9b-6f0e1017494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data map for FDA to FNDDS (updated through 2023)\n",
    "# Run scripts 00b and 00c for details on process, or load in the final mapping file here:\n",
    "\n",
    "fda_map = pd.read_csv('../../data/00/ingredient_matching/fda_fndds_map_2023_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12448820-8e2a-4478-9534-c32a6fc2431d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename the columns for merging\n",
    "wweia_fda = wweia_fda.rename(columns={'Basic Ingredient Description': 'fda_desc'})\n",
    "\n",
    "# select columns to keep\n",
    "wweia_fda = wweia_fda[['SEQN', 'DRXFDCD', 'WWEIA Food Description', 'fda_desc',\n",
    "       'Ingredient Percent', 'DR2ILINE', 'DR2IGRMS', 'diet_day',\n",
    "       'diet_wts', 'RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'RIDEXPRG', 'INDFMPIR',\n",
    "       'DMDEDUC3', 'DMDEDUC2', 'WTINT2YR', 'WTMEC2YR', 'SDMVPSU',\n",
    "       'SDMVSTRA', 'CYCLE']]\n",
    "# merge the data with FDA-FDD\n",
    "wweia_fda = wweia_fda.merge(fda_map, on='fda_desc', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df26f961-77bc-41ee-8d36-ba13bdab4dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.1 percent of line items not mapping from FNDDS to FDA\n"
     ]
    }
   ],
   "source": [
    "# How many missing rows?\n",
    "print(round(673193/(8846306+673193),3)*100, 'percent of line items not mapping from FNDDS to FDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ccb4b6b-20b9-4f8f-9a26-289b4c99a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NAs for ingredients that didn't map from FDAFDD to FNDDS (mainly dehydrated ingredients)\n",
    "wweia_fda = wweia_fda.dropna(subset='Ingredient description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9e8b972-7849-4f09-980e-1453eeeb3668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping FDA descriptions, using the FNDDS descriptions with codes\n",
    "wweia_fda = wweia_fda.drop(columns='fda_desc')\n",
    "wweia_fda.rename(columns={'DRXFDCD': 'foodcode', 'WWEIA Food Description': 'food_description', 'Ingredient description': 'ingred_desc', 'Ingredient code': 'ingred_code', 'Ingredient Percent': 'ingred_wt'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa1c22d6-64b1-4b9b-bd9a-1f5dc17ec057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of unique ingredient descriptions\n",
    "wweia_fda.ingred_desc.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d70c111b-df16-4431-8ed6-11d99a0692ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ingredient nutrient value data, this will provide data on calories per ingredient consumed for adjusting by energy intake in the following script\n",
    "ingred_nutrients = pd.read_csv('../../data/00/ingredient_matching/fndds_all_ingredient_nutrient_values_2023.csv', usecols=['Ingredient code', 'Ingredient description',  'Energy', 'Carbohydrate', 'Fiber, total dietary', 'Fatty acids, total monounsaturated', 'Fatty acids, total polyunsaturated', 'Fatty acids, total saturated', 'Sodium', 'Water'])\n",
    "\n",
    "# rename column\n",
    "ingred_nutrients.rename(columns={'Ingredient code': 'ingred_code'}, inplace=True)\n",
    "\n",
    "# merge the nutrients composition data with out dietary dataset\n",
    "wweia_complete_nutrients = pd.merge(wweia_fda, ingred_nutrients, on = 'ingred_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b9ded58-fbdd-4fc0-89ea-e52dd9e9a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the amount of each ingredient consumed and the quantity of each nutrient consumed per ingredient\n",
    "# Convert the pandas dataframe to Dask dataframe\n",
    "wweia_complete_nutrients_dd = dd.from_pandas(wweia_complete_nutrients, npartitions=10)\n",
    "\n",
    "# Perform the same operations as before but in Dask\n",
    "grouped_wt_sum_dd = wweia_complete_nutrients_dd.groupby(['SEQN', 'foodcode', 'DR2ILINE'])['ingred_wt'].sum().reset_index().rename(columns={'ingred_wt': 'ingred_wt_sum'})\n",
    "\n",
    "# Merge this with the original dataframe.\n",
    "merged_dd = dd.merge(wweia_complete_nutrients_dd, grouped_wt_sum_dd, on=['SEQN', 'foodcode', 'DR2ILINE'])\n",
    "\n",
    "# Calculate the 'Ingred_consumed_g' using vectorized operations.\n",
    "merged_dd['Ingred_consumed_g'] = merged_dd['DR2IGRMS'] * (merged_dd['ingred_wt'] / merged_dd['ingred_wt_sum'])\n",
    "\n",
    "# Convert Dask dataframe back to pandas dataframe\n",
    "wweia_all_recalls = merged_dd.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf49d694-e177-453c-8d51-dc079671b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate intakes for various nutrients. The primary nutrient we need is energy (kcal) to adjust intakes in following script. Additional nutrients are included for those interested in calculating total HEI scores and for carb and fiber\n",
    "wweia_all_recalls.loc[:,['Energy', 'Carbohydrate', 'Fiber, total dietary', 'Fatty acids, total monounsaturated',\t'Fatty acids, total polyunsaturated',\t'Fatty acids, total saturated', 'Sodium']] = wweia_all_recalls.loc[:,['Energy', 'Carbohydrate', 'Fiber, total dietary', 'Fatty acids, total monounsaturated',\t'Fatty acids, total polyunsaturated',\t'Fatty acids, total saturated', 'Sodium', 'Water']].multiply(wweia_all_recalls['Ingred_consumed_g'], axis=0) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed50bc83-f7a0-441c-9771-4061c544fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the ingredient description column as we are using 'ingred_desc' now\n",
    "wweia_all_recalls.drop(columns=['Ingredient description'], inplace=True)\n",
    "\n",
    "# split metadata for combining with averaged recalls in next step\n",
    "metadata = wweia_all_recalls.drop_duplicates(subset='SEQN')\n",
    "metadata = metadata[['SEQN', 'RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'RIDEXPRG', 'INDFMPIR',\n",
    "       'DMDEDUC3', 'DMDEDUC2', 'WTINT2YR', 'WTMEC2YR', 'SDMVPSU', 'SDMVSTRA',\n",
    "       'CYCLE', 'diet_wts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3793dca0-1427-4e46-a62b-d898e30b0b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average intake over 2 diet recall days (ingredients)\n",
    "# sum intakes\n",
    "recalls_sum = wweia_all_recalls.groupby(['SEQN', 'diet_day', 'foodcode', 'food_description', 'ingred_code', 'ingred_desc'])[['Ingred_consumed_g', 'Energy', 'Carbohydrate', 'Fiber, total dietary', 'Fatty acids, total monounsaturated',\t'Fatty acids, total polyunsaturated',\t'Fatty acids, total saturated', 'Sodium', 'Water']].agg(np.sum).reset_index()\n",
    "recalls_sum.set_index(['SEQN', 'diet_day', 'foodcode', 'food_description', 'ingred_code', 'ingred_desc'],inplace=True)\n",
    "r_sum = recalls_sum.unstack(level=['diet_day'], fill_value=0).stack()\n",
    "r_sum.reset_index(inplace=True)\n",
    "\n",
    "# average intakes\n",
    "recalls_mean = r_sum.groupby(['SEQN', 'foodcode', 'food_description', 'ingred_code', 'ingred_desc'])[['Ingred_consumed_g', 'Energy', 'Carbohydrate', 'Fiber, total dietary', 'Fatty acids, total monounsaturated',\t'Fatty acids, total polyunsaturated',\t'Fatty acids, total saturated', 'Sodium', 'Water']].mean().reset_index()\n",
    "\n",
    "# combine with metadata\n",
    "recalls_mean_meta = recalls_mean.merge(metadata, on='SEQN', how='left')\n",
    "\n",
    "# Save dataset\n",
    "recalls_mean_meta.to_csv('../../data/00/wweia_dataset/wweia_ingredients_recalls_2023.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
